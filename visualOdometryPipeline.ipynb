{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python373jvsc74a57bd034d9fd4794b4aa62af7c694b698b8481ba4eb70d629f53257a855dbffddd8207",
   "display_name": "Python 3.7.3 32-bit ('bot': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Visual odometry pipeline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Import requirements"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from ImageProcessor import ImageProcessor\n",
    "from helperScripts.TimeKeeper import TimeKeeper\n",
    "\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "source": [
    "### Load images and depth map"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Selections: 0-21\n"
     ]
    }
   ],
   "source": [
    "folderChoice = 1\n",
    "path = \"\".join([\"testImages/visualOdometryTestImages/\", str(folderChoice)])\n",
    "\n",
    "# Load set of top images\n",
    "imageGlobT = sorted(glob.glob(\"\".join([path, \"/top_*\", \".png\"])))\n",
    "\n",
    "# Load set of bottom images\n",
    "imageGlobB = sorted(glob.glob(\"\".join([path, \"/bottom_*\", \".png\"])))\n",
    "\n",
    "# Load depth map\n",
    "imageGlobD = sorted(glob.glob(\"\".join([path, \"/topDepth_*\", \".png\"])))\n",
    "\n",
    "if not (len(imageGlobT)==len(imageGlobB) and \\\n",
    "                len(imageGlobB)==len(imageGlobD)):\n",
    "    print(\"Images could not be matched\")\n",
    "\n",
    "print (\"Selections: 0-{}\".format(len(imageGlobT)-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "23 23 23\n"
     ]
    }
   ],
   "source": [
    "# Top images\n",
    "imagesT = []\n",
    "for imageFile in imageGlobT:\n",
    "    imagesT.append(cv2.imread(imageFile))\n",
    "\n",
    "# Bottom images\n",
    "imagesB = []\n",
    "for imageFile in imageGlobB:\n",
    "    imagesB.append(cv2.imread(imageFile))\n",
    "\n",
    "# Depth maps; -1 flag to load them as is\n",
    "depthMaps = []\n",
    "for imageFile in imageGlobD:\n",
    "    depthMaps.append(cv2.imread(imageFile, -1))\n",
    "\n",
    "print(len(imagesT), len(imagesB), len(depthMaps))"
   ]
  },
  {
   "source": [
    "### View top camera images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "51c4ff00075841dd8b08026551059df9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xa554aeb0>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "selection = 0\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.suptitle(\"Top images\")\n",
    "plt.imshow(cv2.cvtColor(cv2.rotate(np.hstack([imagesT[selection], imagesT[selection+1]]), cv2.ROTATE_90_CLOCKWISE), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "source": [
    "### View bottom camera images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a99e993272b34b55878ca1d7c772ff3b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xa358df70>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.suptitle(\"Bottom images\")\n",
    "plt.imshow(cv2.cvtColor(cv2.rotate(np.hstack([imagesB[selection], imagesB[selection+1]]), cv2.ROTATE_90_CLOCKWISE), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "source": [
    "### View depth images\n",
    "Depth images correspond to top camera"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1045894e5a724c068d23b7e28137a04c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xa356a8b0>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.suptitle(\"Depth maps\")\n",
    "plt.imshow(cv2.rotate(np.hstack([depthMaps[selection], depthMaps[selection+1]]), cv2.ROTATE_90_CLOCKWISE))"
   ]
  },
  {
   "source": [
    "### Depth map units and dimensions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(640, 360)\n725 mm\n"
     ]
    }
   ],
   "source": [
    "print(depthMaps[0].shape)\n",
    "print(depthMaps[0][int(depthMaps[0].shape[0]/2), \\\n",
    "                    int(depthMaps[0].shape[1]/2)], \"mm\")"
   ]
  },
  {
   "source": [
    "### Instantiating TimeKeeper"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeKeeper = TimeKeeper()"
   ]
  },
  {
   "source": [
    "### Loading camera calibration matrix"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading from data/monoCalibration.json\nLoaded mono calibration\n[[592.63974229   0.         188.47568825]\n [  0.         592.98181459 312.47351841]\n [  0.           0.           1.        ]]\n"
     ]
    }
   ],
   "source": [
    "imageProcessor=ImageProcessor()\n",
    "imageProcessor.loadMonoCalibration()\n",
    "k=imageProcessor.cameraMatrixL\n",
    "print(k)"
   ]
  },
  {
   "source": [
    "### Feature Extraction\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures(orb, image):\n",
    "    \"\"\"Find keypoints and descriptors for the image\"\"\"\n",
    "    keypoints = orb.detect(image, None)\n",
    "    keypoints, descriptors = orb.compute(image, keypoints)\n",
    "    \n",
    "    return keypoints, descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of features detected in frame 0: 500\nCoordinates of first keypoint in frame 0: (119.0, 211.0)\nCompleted in 0.099771 seconds\n"
     ]
    }
   ],
   "source": [
    "timeKeeper.startPerfCounter()\n",
    "\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "keypoints, descriptors = extractFeatures(orb, imagesT[selection])\n",
    "\n",
    "print(\"Number of features detected in frame {}: {}\"\\\n",
    "                                .format(selection, len(keypoints)))\n",
    "print(\"Coordinates of first keypoint in frame {}: {}\"\\\n",
    "                                .format(selection, str(keypoints[0].pt)))\n",
    "\n",
    "timeKeeper.printPerfCounter()"
   ]
  },
  {
   "source": [
    "### Visualize features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeFeatures(image, keypoints, flag):\n",
    "    \"\"\"Visualize extracted features in image\"\"\"\n",
    "    display = cv2.drawKeypoints(image, keypoints, None, flags=flag)\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.imshow(cv2.cvtColor(cv2.rotate(display, cv2.ROTATE_90_CLOCKWISE), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "95908f6c497f4c45806ea3c590f39abc"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "visualizeFeatures(imagesT[selection], keypoints, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c3ad5a9e11a84cb5af519548018e40cd"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "visualizeFeatures(imagesT[selection], keypoints, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAllFeatures(images, extractFeatures, orb):\n",
    "    \"\"\"Find keypoints and descriptors for each image in folder\"\"\"\n",
    "    allKeypoints = []\n",
    "    allDescriptors = []\n",
    "    \n",
    "    for image in images:\n",
    "        keypoints, descriptors = extractFeatures(orb, image)\n",
    "        allKeypoints.append(keypoints)\n",
    "        allDescriptors.append(descriptors)\n",
    "    \n",
    "    return allKeypoints, allDescriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "23 23\nNumber of features detected in frame 0: 500\nCoordinates of the first keypoint in frame 0: (119.0, 211.0)\n\nCompleted in 1.559738 seconds\nAverage time for each extraction: 0.06781\n"
     ]
    }
   ],
   "source": [
    "timeKeeper.startPerfCounter()\n",
    "\n",
    "allKeypoints, allDescriptors = extractAllFeatures(imagesT, extractFeatures, orb)\n",
    "\n",
    "print(len(allKeypoints), len(allDescriptors))\n",
    "\n",
    "print(\"Number of features detected in frame {}: {}\"\\\n",
    "                            .format(selection, len(allKeypoints[selection])))\n",
    "print(\"Coordinates of the first keypoint in frame {}: {}\\n\"\\\n",
    "                            .format(selection, str(allKeypoints[selection][0].pt)))\n",
    "\n",
    "timeKeeper.printPerfCounter()\n",
    "print(\"Average time for each extraction: {:.5f}\".format(timeKeeper.getElapsedTime()/len(imagesT)))"
   ]
  },
  {
   "source": [
    "### Feature matching"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchFeatures(bfMatcher, descriptors0, descriptors1, bestNMatches):\n",
    "    \"\"\"Match features from two images\"\"\"\n",
    "    match = bfMatcher.match(descriptors0, descriptors1)\n",
    "    match = sorted(match, key = lambda x:x.distance)\n",
    "\n",
    "    return match[:bestNMatches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of features matched in frames 0 and 1: 50\nCompleted in 0.024405 seconds\n"
     ]
    }
   ],
   "source": [
    "timeKeeper.startPerfCounter()\n",
    "\n",
    "bfMatcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "bestNMatches = 50\n",
    "\n",
    "match = matchFeatures(bfMatcher, allDescriptors[selection], \\\n",
    "                    allDescriptors[selection+1], bestNMatches)\n",
    "\n",
    "print(\"Number of features matched in frames {} and {}: {}\"\\\n",
    "                        .format(selection, selection+1, len(match)))\n",
    "\n",
    "timeKeeper.printPerfCounter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeMatches(image0, keypoints0, image1, keypoints1, match):\n",
    "    imageMatches = cv2.drawMatches(image0, keypoints0, \\\n",
    "                            image1, keypoints1, match, None, flags=2)\n",
    "\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.imshow(cv2.cvtColor(imageMatches, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d456d916ac7f431e9af3e1b2d1074185"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "visualizeMatches(imagesT[selection], allKeypoints[selection], \\\n",
    "                imagesT[selection+1], allKeypoints[selection+1], match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchAllFeatures(allDescriptors, matchFeatures, bfMatcher, bestNMatches):\n",
    "    \"\"\"Match features for each subsequent image pair in the dataset\"\"\"\n",
    "    matches = []\n",
    "\n",
    "    for i in range(len(allDescriptors)-1):\n",
    "        descriptor1 = allDescriptors[i]\n",
    "        descriptor2 = allDescriptors[i+1]\n",
    "\n",
    "        match = matchFeatures(bfMatcher, descriptor1, descriptor2, bestNMatches)\n",
    "\n",
    "        matches.append(match)\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of features matched in frames 0 and 1: 50\nCompleted in 0.543066 seconds\nAverage time for each frame pair match: 0.02361\n"
     ]
    }
   ],
   "source": [
    "timeKeeper.startPerfCounter()\n",
    "\n",
    "matches = matchAllFeatures(allDescriptors, matchFeatures, bfMatcher, bestNMatches)\n",
    "\n",
    "print(\"Number of features matched in frames {} and {}: {}\"\\\n",
    "            .format(selection, selection+1, len(matches[selection])))\n",
    "\n",
    "timeKeeper.printPerfCounter()\n",
    "print(\"Average time for each frame pair match: {:.5f}\".format(timeKeeper.getElapsedTime()/len(imagesT)))"
   ]
  },
  {
   "source": [
    "### Trajectory Estimation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimateMotion(match, keypoints0, keypoints1, k, depthMap=None):\n",
    "    \"\"\"Estimate camera motion from a pair of subsequent image frames\"\"\"\n",
    "    rmat=np.eye(3)\n",
    "    tvec=np.zeros((3,1))\n",
    "    imagePoints0 = []\n",
    "    imagePoints1 = []\n",
    "\n",
    "    for m in match:\n",
    "        train_idx = m.trainIdx\n",
    "        query_idx = m.queryIdx\n",
    "\n",
    "        p1x, p1y = keypoints0[query_idx].pt \n",
    "        imagePoints0.append([p1x,p1y])\n",
    "\n",
    "        p2x,p2y = keypoints1[train_idx].pt \n",
    "        imagePoints1.append([p2x,p2y])\n",
    "\n",
    "    E, mask = cv2.findEssentialMat(\\\n",
    "                        np.array(imagePoints0), np.array(imagePoints1), k) \n",
    "\n",
    "    retval, rmat, tvec, mask = cv2.recoverPose(\\\n",
    "                        E, np.array(imagePoints0), np.array(imagePoints1), k)\n",
    "\n",
    "    return rmat, tvec, imagePoints0, imagePoints1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Estimated rotation:\n [[ 0.99750987  0.0699073  -0.00932918]\n [-0.07047992  0.98324925 -0.16808777]\n [-0.00257765  0.16832673  0.98572789]]\nEstimated translation:\n [[-0.12298415]\n [-0.36366204]\n [ 0.92337686]]\nCompleted in 0.777090 seconds\n"
     ]
    }
   ],
   "source": [
    "timeKeeper.startPerfCounter()\n",
    "\n",
    "match = matches[selection]\n",
    "rmat, tvec, imagePoints0, imagePoints1 = estimateMotion(\\\n",
    "                        match, allKeypoints[selection], \\\n",
    "                        allKeypoints[selection+1], k, \\\n",
    "                        depthMap=depthMaps[selection])\n",
    "\n",
    "print(\"Estimated rotation:\\n {0}\".format(rmat))\n",
    "print(\"Estimated translation:\\n {0}\".format(tvec))\n",
    "\n",
    "timeKeeper.printPerfCounter()"
   ]
  },
  {
   "source": [
    "### Camera movement visualization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeCameraMovement(image0, imagePoints0, \\\n",
    "                image1, imagePoints1, showImageAfterMove=False):\n",
    "    \"\"\"Visualize camera movement across frames\"\"\"\n",
    "    image0 = image0.copy()\n",
    "    image1 = image1.copy()\n",
    "\n",
    "    for i in range(0, len(imagePoints0)):\n",
    "        # Coordinates of a point on t frame\n",
    "        p1 = (int(imagePoints0[i][0]), int(imagePoints0[i][1]))\n",
    "        # Coordinates of the same point on t+1 frame\n",
    "        p2 = (int(imagePoints1[i][0]), int(imagePoints1[i][1]))\n",
    "\n",
    "        cv2.circle(image0, p1, 5, (0, 255, 0), 1)\n",
    "        cv2.arrowedLine(image0, p1, p2, (0, 255, 0), 1)\n",
    "        cv2.circle(image0, p2, 5, (255, 0, 0), 1)\n",
    "\n",
    "        if showImageAfterMove:\n",
    "            cv2.circle(image1, p2, 5, (255, 0, 0), 1)\n",
    "    \n",
    "    if showImageAfterMove: \n",
    "        return image1\n",
    "    else:\n",
    "        return image0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "475e4d1394e24ffb90b204b68e9780d2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x9e8c52f0>"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "imageMovementBefore = visualizeCameraMovement(imagesT[selection], \\\n",
    "                    imagePoints0, imagesT[selection+1], imagePoints1)\n",
    "\n",
    "imageMovementAfter = visualizeCameraMovement(imagesT[selection], \\\n",
    "                    imagePoints0, imagesT[selection+1], imagePoints1, \\\n",
    "                    showImageAfterMove=True)\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(cv2.cvtColor(np.hstack([imageMovementBefore, imageMovementAfter]), \\\n",
    "                                                        cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "source": [
    "### Camera Trajectory Estimation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimateTrajectory(estimateMotion, matches, allKeypoints, k, depthMaps):\n",
    "    \"\"\"Estimate complete camera trajectory from subsequent image pairs\"\"\"\n",
    "    trajectory = [np.array([0, 0, 0])]\n",
    "\n",
    "    R = np.diag([1,1,1])\n",
    "    T = np.zeros([3, 1])\n",
    "    RT = np.hstack([R, T])\n",
    "    RT = np.vstack([RT, np.zeros([1, 4])])\n",
    "    RT[-1, -1] = 1\n",
    "\n",
    "    for i in range(len(matches)):     \n",
    "        match = matches[i]\n",
    "        keypoints0 = allKeypoints[i]\n",
    "        keypoints1 = allKeypoints[i+1]\n",
    "        depth = depthMaps[i]\n",
    "\n",
    "        rmat, tvec, imagePoints0, imagePoints1 = estimateMotion(\\\n",
    "                                match, keypoints0, keypoints1, k, depthMap=depth)\n",
    "\n",
    "        rt_mtx = np.hstack([rmat, tvec])\n",
    "        rt_mtx = np.vstack([rt_mtx, np.zeros([1, 4])])\n",
    "        rt_mtx[-1, -1] = 1\n",
    "\n",
    "        rt_mtx_inv = np.linalg.inv(rt_mtx)\n",
    "        \n",
    "        RT = np.dot(RT, rt_mtx_inv)\n",
    "        newTrajectory = RT[:3, 3]\n",
    "        trajectory.append(newTrajectory)\n",
    "\n",
    "    trajectory = np.array(trajectory)\n",
    "\n",
    "    return trajectory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Camera location in point 0 is: \n [0. 0. 0.]\n\nCamera location in point 1 is: \n [ 0.09942718  0.21073892 -0.9724728 ]\n\nLength of trajectory: 23\nCompleted in 3.043266 seconds\nAverage time for trajectory segment: 0.13232\n"
     ]
    }
   ],
   "source": [
    "timeKeeper.startPerfCounter()\n",
    "\n",
    "trajectory = estimateTrajectory(estimateMotion, matches, \\\n",
    "                            allKeypoints, k, depthMaps=depthMaps)\n",
    "\n",
    "print(\"Camera location in point {} is: \\n {}\\n\"\\\n",
    "                        .format(selection, trajectory[selection,:]))\n",
    "print(\"Camera location in point {} is: \\n {}\\n\"\\\n",
    "                        .format(selection+1, trajectory[selection+1,:]))\n",
    "print(\"Length of trajectory: {}\".format(trajectory.shape[0]))\n",
    "\n",
    "timeKeeper.printPerfCounter()\n",
    "print(\"Average time for trajectory segment: {:.5f}\".format(timeKeeper.getElapsedTime()/len(imagesT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeTrajectory(trajectory):\n",
    "    \"\"\"Show a 3D plot of the trajectory\"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "    ax.plot(trajectory[:,0], \\\n",
    "            trajectory[:,1], \\\n",
    "            trajectory[:,2])\n",
    "\n",
    "    ax.set_xlabel(\"$x$\")\n",
    "    ax.set_ylabel(\"$y$\")\n",
    "    ax.set_zlabel(\"$z$\")\n",
    "\n",
    "    ax.set_xlim(-5,5)\n",
    "    ax.set_ylim(-5,5)\n",
    "    ax.set_zlim(-5,5)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "28a280de6801418598b3c92bb1d94bba"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "visualizeTrajectory(trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}