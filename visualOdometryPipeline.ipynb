{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd01b74fdc6a0069e63d7c35520416cfe241b2e1d296eedc56ee9c4fe2929446925",
   "display_name": "Python 3.6.8  ('bot': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "1b74fdc6a0069e63d7c35520416cfe241b2e1d296eedc56ee9c4fe2929446925"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Visual odometry pipeline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Import requirements"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from ImageProcessor import ImageProcessor\n",
    "from StereoMatcher import StereoMatcher\n",
    "from VoxelGrid import VoxelGrid\n",
    "from helperScripts.TimeKeeper import TimeKeeper\n",
    "\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "source": [
    "### Load images and depth map"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Selections: 0-13\n"
     ]
    }
   ],
   "source": [
    "folderChoice = 2\n",
    "path = \"\".join([\"testImages/visualOdometryTestImages/\", str(folderChoice)])\n",
    "\n",
    "# Load set of top images\n",
    "imageGlobT = sorted(glob.glob(\"\".join([path, \"/top_*\", \".png\"])))\n",
    "\n",
    "# Load set of bottom images\n",
    "imageGlobB = sorted(glob.glob(\"\".join([path, \"/bottom_*\", \".png\"])))\n",
    "\n",
    "# Load depth map\n",
    "imageGlobD = sorted(glob.glob(\"\".join([path, \"/topDepth_*\", \".png\"])))\n",
    "\n",
    "if not (len(imageGlobT)==len(imageGlobB) and \\\n",
    "                len(imageGlobB)==len(imageGlobD)):\n",
    "    print(\"Images could not be matched\")\n",
    "\n",
    "print (\"Selections: 0-{}\".format(len(imageGlobT)-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "15 15 15\n"
     ]
    }
   ],
   "source": [
    "# Top images\n",
    "imagesT = []\n",
    "for imageFile in imageGlobT:\n",
    "    imagesT.append(cv2.imread(imageFile))\n",
    "\n",
    "# Bottom images\n",
    "imagesB = []\n",
    "for imageFile in imageGlobB:\n",
    "    imagesB.append(cv2.imread(imageFile))\n",
    "\n",
    "# Depth maps; -1 flag to load them as is\n",
    "depthMaps = []\n",
    "for imageFile in imageGlobD:\n",
    "    depthMaps.append(cv2.imread(imageFile, -1))\n",
    "\n",
    "print(len(imagesT), len(imagesB), len(depthMaps))"
   ]
  },
  {
   "source": [
    "### View top camera images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "26f38f332cf2495d872737607afb5cdd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c489914940>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "selection = 0\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.suptitle(\"Top images\")\n",
    "plt.imshow(cv2.cvtColor(cv2.rotate(np.hstack([imagesT[selection], imagesT[selection+1]]), cv2.ROTATE_90_CLOCKWISE), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "source": [
    "### View bottom camera images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e40fa4ea705748f580a4cb2b147887b4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c489c08b00>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.suptitle(\"Bottom images\")\n",
    "plt.imshow(cv2.cvtColor(cv2.rotate(np.hstack([imagesB[selection], imagesB[selection+1]]), cv2.ROTATE_90_CLOCKWISE), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "source": [
    "### View depth images\n",
    "Depth images correspond to top camera"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53b0fc39160047108791de02601e93ec"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c48b4f40f0>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.suptitle(\"Depth maps\")\n",
    "plt.imshow(cv2.rotate(np.hstack([depthMaps[selection], depthMaps[selection+1]]), cv2.ROTATE_90_CLOCKWISE))"
   ]
  },
  {
   "source": [
    "### Depth map units and dimensions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(640, 360)\n541 mm\n"
     ]
    }
   ],
   "source": [
    "print(depthMaps[0].shape)\n",
    "print(depthMaps[0][int(depthMaps[0].shape[0]/2), \\\n",
    "                    int(depthMaps[0].shape[1]/2)], \"mm\")"
   ]
  },
  {
   "source": [
    "### Instantiating TimeKeeper"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeKeeper = TimeKeeper()"
   ]
  },
  {
   "source": [
    "### Loading camera calibration matrix"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading from data/monoCalibration.json\nLoaded mono calibration\nReading from data/parametersSGBM.json\n[[ 0  0 -1]\n [ 0  1  0]\n [ 1  0  0]]\n[[592.63974229   0.         188.47568825]\n [  0.         592.98181459 312.47351841]\n [  0.           0.           1.        ]]\n"
     ]
    }
   ],
   "source": [
    "imageProcessor = ImageProcessor()\n",
    "imageProcessor.loadMonoCalibration()\n",
    "\n",
    "stereoMatcher = StereoMatcher(imageProcessor=imageProcessor)\n",
    "\n",
    "voxelGrid = VoxelGrid(stereoMatcher=stereoMatcher, imageProcessor=imageProcessor)\n",
    "\n",
    "baseRotation = voxelGrid.redefineRotationMatrix\n",
    "k=imageProcessor.cameraMatrixL\n",
    "\n",
    "print(baseRotation)\n",
    "print(k)"
   ]
  },
  {
   "source": [
    "### Feature Extraction\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures(orb, image):\n",
    "    \"\"\"Find keypoints and descriptors for the image\"\"\"\n",
    "    keypoints = orb.detect(image, None)\n",
    "    keypoints, descriptors = orb.compute(image, keypoints)\n",
    "    \n",
    "    return keypoints, descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of features detected in frame 0: 500\nCoordinates of first keypoint in frame 0: (288.0, 130.0)\nCompleted in 0.108893 seconds\n"
     ]
    }
   ],
   "source": [
    "timeKeeper.startPerfCounter()\n",
    "\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "keypoints, descriptors = extractFeatures(orb, imagesT[selection])\n",
    "\n",
    "print(\"Number of features detected in frame {}: {}\"\\\n",
    "                                .format(selection, len(keypoints)))\n",
    "print(\"Coordinates of first keypoint in frame {}: {}\"\\\n",
    "                                .format(selection, str(keypoints[0].pt)))\n",
    "\n",
    "timeKeeper.printPerfCounter()"
   ]
  },
  {
   "source": [
    "### Visualize features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeFeatures(image, keypoints, flag):\n",
    "    \"\"\"Visualize extracted features in image\"\"\"\n",
    "    display = cv2.drawKeypoints(image, keypoints, None, flags=flag)\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.imshow(cv2.cvtColor(cv2.rotate(display, cv2.ROTATE_90_CLOCKWISE), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c38e809450548e2a53413b084503997"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "visualizeFeatures(imagesT[selection], keypoints, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "145e4fd5e119420299e172482383c623"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "visualizeFeatures(imagesT[selection], keypoints, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAllFeatures(images, extractFeatures, orb):\n",
    "    \"\"\"Find keypoints and descriptors for each image in folder\"\"\"\n",
    "    allKeypoints = []\n",
    "    allDescriptors = []\n",
    "    \n",
    "    for image in images:\n",
    "        keypoints, descriptors = extractFeatures(orb, image)\n",
    "        allKeypoints.append(keypoints)\n",
    "        allDescriptors.append(descriptors)\n",
    "    \n",
    "    return allKeypoints, allDescriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "15 15\nNumber of features detected in frame 0: 500\nCoordinates of the first keypoint in frame 0: (288.0, 130.0)\n\nCompleted in 0.116350 seconds\nAverage time for each extraction: 0.00776\n"
     ]
    }
   ],
   "source": [
    "timeKeeper.startPerfCounter()\n",
    "\n",
    "allKeypoints, allDescriptors = extractAllFeatures(imagesT, extractFeatures, orb)\n",
    "\n",
    "print(len(allKeypoints), len(allDescriptors))\n",
    "\n",
    "print(\"Number of features detected in frame {}: {}\"\\\n",
    "                            .format(selection, len(allKeypoints[selection])))\n",
    "print(\"Coordinates of the first keypoint in frame {}: {}\\n\"\\\n",
    "                            .format(selection, str(allKeypoints[selection][0].pt)))\n",
    "\n",
    "timeKeeper.printPerfCounter()\n",
    "print(\"Average time for each extraction: {:.5f}\".format(timeKeeper.getElapsedTime()/len(imagesT)))"
   ]
  },
  {
   "source": [
    "### Feature matching"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchFeatures(bfMatcher, descriptors0, descriptors1, bestNMatches):\n",
    "    \"\"\"Match features from two images\"\"\"\n",
    "    match = bfMatcher.match(descriptors0, descriptors1)\n",
    "    match = sorted(match, key = lambda x:x.distance)\n",
    "\n",
    "    return match[:bestNMatches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of features matched in frames 0 and 1: 50\nCompleted in 0.002412 seconds\n"
     ]
    }
   ],
   "source": [
    "timeKeeper.startPerfCounter()\n",
    "\n",
    "bfMatcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "bestNMatches = 50\n",
    "\n",
    "match = matchFeatures(bfMatcher, allDescriptors[selection], \\\n",
    "                    allDescriptors[selection+1], bestNMatches)\n",
    "\n",
    "print(\"Number of features matched in frames {} and {}: {}\"\\\n",
    "                        .format(selection, selection+1, len(match)))\n",
    "\n",
    "timeKeeper.printPerfCounter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeMatches(image0, keypoints0, image1, keypoints1, match):\n",
    "    imageMatches = cv2.drawMatches(image0, keypoints0, \\\n",
    "                            image1, keypoints1, match, None, flags=2)\n",
    "\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.imshow(cv2.cvtColor(imageMatches, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4ccc42c22323443c972600530f966a3b"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "visualizeMatches(imagesT[selection], allKeypoints[selection], \\\n",
    "                imagesT[selection+1], allKeypoints[selection+1], match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchAllFeatures(allDescriptors, matchFeatures, bfMatcher, bestNMatches):\n",
    "    \"\"\"Match features for each subsequent image pair in the dataset\"\"\"\n",
    "    matches = []\n",
    "\n",
    "    for i in range(len(allDescriptors)-1):\n",
    "        descriptor1 = allDescriptors[i]\n",
    "        descriptor2 = allDescriptors[i+1]\n",
    "\n",
    "        match = matchFeatures(bfMatcher, descriptor1, descriptor2, bestNMatches)\n",
    "\n",
    "        matches.append(match)\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of features matched in frames 0 and 1: 50\nCompleted in 0.016041 seconds\nAverage time for each frame pair match: 0.00107\n"
     ]
    }
   ],
   "source": [
    "timeKeeper.startPerfCounter()\n",
    "\n",
    "matches = matchAllFeatures(allDescriptors, matchFeatures, bfMatcher, bestNMatches)\n",
    "\n",
    "print(\"Number of features matched in frames {} and {}: {}\"\\\n",
    "            .format(selection, selection+1, len(matches[selection])))\n",
    "\n",
    "timeKeeper.printPerfCounter()\n",
    "print(\"Average time for each frame pair match: {:.5f}\".format(timeKeeper.getElapsedTime()/len(imagesT)))"
   ]
  },
  {
   "source": [
    "### Trajectory Estimation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimateMotion(match, keypoints0, keypoints1, k, depthMap=None, usePnP=False):\n",
    "    \"\"\"Estimate camera motion from a pair of subsequent image frames\"\"\"\n",
    "    rmat=np.eye(3)\n",
    "    tvec=np.zeros((3,1))\n",
    "    imagePoints0 = []\n",
    "    imagePoints1 = []\n",
    "\n",
    "    for m in match:\n",
    "        train_idx = m.trainIdx\n",
    "        query_idx = m.queryIdx\n",
    "\n",
    "        p1x, p1y = keypoints0[query_idx].pt \n",
    "        imagePoints0.append([p1x,p1y])\n",
    "\n",
    "        p2x,p2y = keypoints1[train_idx].pt \n",
    "        imagePoints1.append([p2x,p2y])\n",
    "    \n",
    "    E, mask = cv2.findEssentialMat(\\\n",
    "                    np.array(imagePoints0), np.array(imagePoints1), k, \\\n",
    "                    cv2.RANSAC, 0.999, 1.0) \n",
    "\n",
    "    retval, rmat, tvec, mask = cv2.recoverPose(E, np.array(imagePoints0), \\\n",
    "                    np.array(imagePoints1), k)\n",
    "\n",
    "    return rmat, tvec, imagePoints0, imagePoints1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Estimated rotation:\n [[ 0.99922616  0.03659853 -0.01440941]\n [-0.03542763  0.99659124  0.0745036 ]\n [ 0.01708701 -0.07393546  0.99711663]]\nEstimated translation:\n [[ 0.27732344]\n [ 0.15106652]\n [-0.94882592]]\nCompleted in 0.002784 seconds\n"
     ]
    }
   ],
   "source": [
    "timeKeeper.startPerfCounter()\n",
    "\n",
    "match = matches[selection]\n",
    "rmat, tvec, imagePoints0, imagePoints1 = estimateMotion(\\\n",
    "                        match, allKeypoints[selection], \\\n",
    "                        allKeypoints[selection+1], k, \\\n",
    "                        depthMap=depthMaps[selection])\n",
    "\n",
    "print(\"Estimated rotation:\\n {0}\".format(rmat))\n",
    "print(\"Estimated translation:\\n {0}\".format(tvec))\n",
    "\n",
    "timeKeeper.printPerfCounter()"
   ]
  },
  {
   "source": [
    "### Camera movement visualization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeCameraMovement(image0, imagePoints0, \\\n",
    "                image1, imagePoints1, showImageAfterMove=False):\n",
    "    \"\"\"Visualize camera movement across frames\"\"\"\n",
    "    image0 = image0.copy()\n",
    "    image1 = image1.copy()\n",
    "\n",
    "    for i in range(0, len(imagePoints0)):\n",
    "        # Coordinates of a point on t frame\n",
    "        p1 = (int(imagePoints0[i][0]), int(imagePoints0[i][1]))\n",
    "        # Coordinates of the same point on t+1 frame\n",
    "        p2 = (int(imagePoints1[i][0]), int(imagePoints1[i][1]))\n",
    "\n",
    "        cv2.circle(image0, p1, 5, (0, 255, 0), 1)\n",
    "        cv2.arrowedLine(image0, p1, p2, (0, 255, 0), 1)\n",
    "        cv2.circle(image0, p2, 5, (255, 0, 0), 1)\n",
    "\n",
    "        if showImageAfterMove:\n",
    "            cv2.circle(image1, p2, 5, (255, 0, 0), 1)\n",
    "    \n",
    "    if showImageAfterMove: \n",
    "        return image1\n",
    "    else:\n",
    "        return image0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa4f3452a9094dcb88101eb880d80e90"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c48bb99748>"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "imageMovementBefore = visualizeCameraMovement(imagesT[selection], \\\n",
    "                    imagePoints0, imagesT[selection+1], imagePoints1)\n",
    "\n",
    "imageMovementAfter = visualizeCameraMovement(imagesT[selection], \\\n",
    "                    imagePoints0, imagesT[selection+1], imagePoints1, \\\n",
    "                    showImageAfterMove=True)\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(cv2.cvtColor(np.hstack([imageMovementBefore, imageMovementAfter]), \\\n",
    "                                                        cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "source": [
    "### Camera Trajectory Estimation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimateTrajectory(estimateMotion, matches, allKeypoints, k, \\\n",
    "                                                baseRotation, depthMaps):\n",
    "    \"\"\"Estimate complete camera trajectory from subsequent image pairs\"\"\"\n",
    "    trajectory = [np.array([0, 0, 0])]\n",
    "    rotation = [baseRotation]\n",
    "    #rotation = [np.eye(3)]\n",
    "\n",
    "    #R = np.diag([1,1,1])\n",
    "    R = baseRotation.copy().T\n",
    "    T = np.zeros([3, 1])\n",
    "    RT = np.hstack([R, T])\n",
    "    RT = np.vstack([RT, np.zeros([1, 4])])\n",
    "    RT[-1, -1] = 1\n",
    "\n",
    "    for i in range(len(matches)):     \n",
    "        match = matches[i]\n",
    "        keypoints0 = allKeypoints[i]\n",
    "        keypoints1 = allKeypoints[i+1]\n",
    "        depth = depthMaps[i]\n",
    "\n",
    "        rmat, tvec, imagePoints0, imagePoints1 = estimateMotion(\\\n",
    "                                match, keypoints0, keypoints1, k, depthMap=depth)\n",
    "\n",
    "        rt_mtx = np.hstack([rmat, tvec])\n",
    "        rt_mtx = np.vstack([rt_mtx, np.zeros([1, 4])])\n",
    "        rt_mtx[-1, -1] = 1\n",
    "\n",
    "        rt_mtx_inv = np.linalg.inv(rt_mtx)\n",
    "        \n",
    "        RT = np.dot(RT, rt_mtx_inv)\n",
    "\n",
    "        newTrajectory = RT[:3, 3]\n",
    "        newRotation = RT[:3, :3]\n",
    "\n",
    "        trajectory.append(newTrajectory*100)\n",
    "        rotation.append(newRotation)\n",
    "\n",
    "    trajectory = np.array(trajectory)\n",
    "    rotation = np.array(rotation)\n",
    "\n",
    "    return trajectory, rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Camera location in point 0 is: \n [0. 0. 0.]\n\nCamera location in point 1 is: \n [ 93.88311705 -23.08530782  25.55443007]\n\nLength of trajectory: 15\nCompleted in 0.040066 seconds\nAverage time for trajectory segment: 0.00267\n"
     ]
    }
   ],
   "source": [
    "timeKeeper.startPerfCounter()\n",
    "\n",
    "trajectory, rotation = estimateTrajectory(\\\n",
    "                        estimateMotion, matches, allKeypoints, k, \\\n",
    "                        baseRotation, depthMaps=depthMaps)\n",
    "\n",
    "print(\"Camera location in point {} is: \\n {}\\n\"\\\n",
    "                        .format(selection, trajectory[selection,:]))\n",
    "print(\"Camera location in point {} is: \\n {}\\n\"\\\n",
    "                        .format(selection+1, trajectory[selection+1,:]))\n",
    "print(\"Length of trajectory: {}\".format(trajectory.shape[0]))\n",
    "\n",
    "timeKeeper.printPerfCounter()\n",
    "print(\"Average time for trajectory segment: {:.5f}\"\\\n",
    "                        .format(timeKeeper.getElapsedTime()/len(imagesT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Trajectory at each step:\n [[   0.            0.            0.        ]\n [  93.88311705  -23.08530782   25.55443007]\n [ 148.75360795    6.04569682  -52.80763854]\n [ 137.39707564  -80.31847456 -101.9223927 ]\n [ 152.88985462   15.62461675  -78.36614025]\n [ 175.37053792  -67.91578141 -128.52210454]\n [ 102.66991199 -133.0658341  -106.84055427]\n [ 170.43084578  -73.7897505   -63.31123353]\n [ 141.01551565 -141.74902843 -130.5144693 ]\n [ 109.64400133 -225.4749662  -175.30057688]\n [  89.16537986 -301.5769965  -236.85629999]\n [  38.10191529 -373.87856344 -283.38592501]\n [ -50.78841314 -416.7396086  -267.21680879]\n [-122.99909403 -477.17270543 -300.88368232]\n [-144.0208982  -566.44703651 -340.7356278 ]]\n\nRotation at each step:\n [[[ 0.          0.         -1.        ]\n  [ 0.          1.          0.        ]\n  [ 1.          0.          0.        ]]\n\n [[-0.01440941  0.0745036   0.99711663]\n  [ 0.03659853  0.99659124 -0.07393546]\n  [-0.99922616  0.03542763 -0.01708701]]\n\n [[-0.0089741   0.15467274  0.987925  ]\n  [ 0.07259507  0.9854586  -0.15362715]\n  [-0.99732112  0.07033982 -0.02007209]]\n\n [[ 0.02211784  0.13604975  0.99045508]\n  [ 0.09789719  0.98564159 -0.1375747 ]\n  [-0.99495072  0.10000562  0.00848138]]\n\n [[ 0.01321331  0.25442409  0.96700248]\n  [ 0.146211    0.95620059 -0.2535799 ]\n  [-0.98916518  0.14473703 -0.02456503]]\n\n [[ 0.02012459  0.32062188  0.94699346]\n  [ 0.1689909   0.9324661  -0.31929461]\n  [-0.98541214  0.16645895 -0.03541669]]\n\n [[-0.01424634  0.32834706  0.94444971]\n  [ 0.2124867   0.92396561 -0.31802036]\n  [-0.9770601   0.19615238 -0.08293251]]\n\n [[ 0.00718355  0.3859092   0.9225088 ]\n  [ 0.23556971  0.89591575 -0.37661902]\n  [-0.97183091  0.22002059 -0.08447267]]\n\n [[ 0.03034808  0.39202362  0.91945445]\n  [ 0.24610756  0.88862784 -0.38700339]\n  [-0.96876729  0.2380295  -0.06951183]]\n\n [[ 0.04690336  0.43076414  0.90124488]\n  [ 0.26835744  0.86363496 -0.42675397]\n  [-0.96217689  0.26187196 -0.07509138]]\n\n [[ 0.10060812  0.42804119  0.89814183]\n  [ 0.26287573  0.85920614 -0.43893184]\n  [-0.95956988  0.2802598  -0.02607853]]\n\n [[ 0.12600178  0.44894045  0.88463327]\n  [ 0.27793878  0.84005024 -0.46590302]\n  [-0.95229911  0.3045785  -0.01893013]]\n\n [[ 0.13623549  0.50327595  0.85331894]\n  [ 0.31589591  0.79431758 -0.51891169]\n  [-0.93896201  0.34025416 -0.05076857]]\n\n [[ 0.14242505  0.549313    0.82338954]\n  [ 0.3402776   0.75399384 -0.56187582]\n  [-0.92947634  0.36020621 -0.0795313 ]]\n\n [[ 0.17450097  0.60751808  0.77490076]\n  [ 0.36412178  0.69137531 -0.62403166]\n  [-0.91485777  0.39105237 -0.1005649 ]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Trajectory at each step:\\n\", trajectory)\n",
    "print(\"\\nRotation at each step:\\n\", rotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeTrajectory(trajectory):\n",
    "    \"\"\"Show a 3D plot of the trajectory\"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "    ax.plot(trajectory[:,0], \\\n",
    "            trajectory[:,1], \\\n",
    "            trajectory[:,2])\n",
    "\n",
    "    ax.set_xlabel(\"$x$\")\n",
    "    ax.set_ylabel(\"$y$\")\n",
    "    ax.set_zlabel(\"$z$\")\n",
    "\n",
    "    ax.set_xlim(-1000,1000)\n",
    "    ax.set_ylim(-1000,1000)\n",
    "    ax.set_zlim(-1000,1000)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "017fe6c0b49a48798137a3f2e32867c7"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "visualizeTrajectory(trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}