{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python368jvsc74a57bd01b74fdc6a0069e63d7c35520416cfe241b2e1d296eedc56ee9c4fe2929446925",
   "display_name": "Python 3.6.8 64-bit ('bot': venv)",
   "language": "python"
  },
  "metadata": {
   "interpreter": {
    "hash": "1b74fdc6a0069e63d7c35520416cfe241b2e1d296eedc56ee9c4fe2929446925"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Voxel pipeline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Import requirements"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from ImageProcessor import ImageProcessor\n",
    "from StereoMatcher import StereoMatcher\n",
    "from helperScripts.TimeKeeper import TimeKeeper\n",
    "from VoxelGrid import VoxelGrid\n",
    "\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "source": [
    "### Load calibrations and other data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading from data/monoCalibration.json\nLoaded mono calibration\nReading from data/stereoCalibration.json\nLoaded stereo calibration\nReading from data/cameraProperties.json\nLoaded camera properties\nReading from data/stereoRectify.json\nLoaded stereo rectification data\n"
     ]
    }
   ],
   "source": [
    "imageProcessor = ImageProcessor()\n",
    "imageProcessor.verbose = True\n",
    "imageProcessor.loadMonoCalibration()\n",
    "imageProcessor.loadStereoCalibration()\n",
    "imageProcessor.loadCameraProperties()\n",
    "imageProcessor.loadStereoRectify()"
   ]
  },
  {
   "source": [
    "### Create stereo matcher"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading from data/parametersSGBM.json\n"
     ]
    }
   ],
   "source": [
    "stereoMatcher = StereoMatcher(imageProcessor=imageProcessor, \\\n",
    "                matcher=\"SGBM\", vertical=True, createRightMatcher=False)\n",
    "\n",
    "imageProcessor.initUndistortRectifyMap()\n",
    "#stereoMatcher.createDisparityWLSFilter()"
   ]
  },
  {
   "source": [
    "### Timekeeper for performance metrics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeKeeper = TimeKeeper()"
   ]
  },
  {
   "source": [
    "### Loading images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Selections: 0-0\n"
     ]
    }
   ],
   "source": [
    "path = \"testImages/voxelTestImages\"\n",
    "imageGlobL = sorted(glob.glob(\"\".join([path, \"/top_*\", \".png\"])))\n",
    "imageGlobR = sorted(glob.glob(\"\".join([path, \"/bottom_*\", \".png\"])))\n",
    "print (\"Selections: 0-{}\".format(len(imageGlobL)-1))"
   ]
  },
  {
   "source": [
    "### Select image pair and display"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "90de3414213a412c8b5163260b280fa7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2090cef1cf8>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "imageStart = 0\n",
    "imageSelection = [imageStart, imageStart+1]\n",
    "\n",
    "def loadImages(imageNumber):\n",
    "    imageL = cv2.imread(imageGlobL[imageNumber])\n",
    "    imageR = cv2.imread(imageGlobR[imageNumber])\n",
    "\n",
    "    return imageL, imageR\n",
    "\n",
    "imageL, imageR = loadImages(imageSelection[0])\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(np.hstack([imageL, imageR]), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "source": [
    "### Convert to grayscale and undistort"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageProcessor.convertToGrayscale(imageL, imageR)\n",
    "imageProcessor.undistortRectifyRemap(imageProcessor.grayImageL, \\\n",
    "                                        imageProcessor.grayImageR)"
   ]
  },
  {
   "source": [
    "### View undistorted image"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4cad40624c614bd39c73ed4bbe4a640a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2090d1367f0>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle(\"left/right undistorted\")\n",
    "plt.imshow(cv2.cvtColor(np.hstack([imageProcessor.undistortImageL, \\\n",
    "            imageProcessor.undistortImageR]), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d8fecc307f434ec1a968aaffe6abe4ea"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2090d83ee10>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle(\"horizontal epipolar\")\n",
    "plt.imshow(cv2.cvtColor(imageProcessor.drawHorEpipolarLines(\\\n",
    "        imageProcessor.undistortImageL, imageProcessor.undistortImageR), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6551e5108d7d48808b98a711469e2544"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2090d8b7438>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(6,15))\n",
    "fig.suptitle(\"left/right undistorted\")\n",
    "plt.imshow(cv2.cvtColor(imageProcessor.drawVertEpipolarLines(\\\n",
    "        imageProcessor.undistortImageL, imageProcessor.undistortImageR), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "source": [
    "### Compute disparity map"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "minDisparity: 9.0\nmaxDisparity: 41.0\n"
     ]
    }
   ],
   "source": [
    "stereoMatcher.computeDisparity(\\\n",
    "                grayImageL=imageProcessor.undistortImageL, \\\n",
    "                grayImageR=imageProcessor.undistortImageR)\n",
    "\n",
    "stereoMatcher.clampDisparity()\n",
    "stereoMatcher.applyClosingFilter()\n",
    "#stereoMatcher.applyWLSFilterDisparity()\n",
    "\n",
    "print (\"minDisparity:\", stereoMatcher.disparityMapL.min())\n",
    "print (\"maxDisparity:\", stereoMatcher.disparityMapL.max())"
   ]
  },
  {
   "source": [
    "### View disparity map"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "47705ab1e2ea446195be84af9d865294"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2090d919860>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(cv2.rotate(stereoMatcher.disparityMapL, \\\n",
    "    cv2.ROTATE_90_CLOCKWISE))"
   ]
  },
  {
   "source": [
    "### Compute depth map"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9.0\n41.0\n(640, 360)\n481.33795\n2192.7617\n"
     ]
    }
   ],
   "source": [
    "focalLength = imageProcessor.projectionMatrixL[0][0] # changes with rectify?\n",
    "baseline = 32 # mm, measured irl\n",
    "\n",
    "stereoMatcher.disparityMapL[stereoMatcher.disparityMapL==0] = 0.9\n",
    "stereoMatcher.disparityMapL[stereoMatcher.disparityMapL==-1] = 0.9\n",
    "\n",
    "depthMap = np.empty_like(stereoMatcher.disparityMapL)\n",
    "depthMap = (focalLength*baseline)/stereoMatcher.disparityMapL[:]\n",
    "\n",
    "print (stereoMatcher.disparityMapL.min())\n",
    "print (stereoMatcher.disparityMapL.max())\n",
    "print (depthMap.shape)\n",
    "print (depthMap.min())\n",
    "print (depthMap.max())"
   ]
  },
  {
   "source": [
    "### View depth map"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2ac138ecbf3742788e9996e329205b1f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2090d9664a8>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(cv2.rotate(depthMap, cv2.ROTATE_90_CLOCKWISE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use to save images\n",
    "# _=cv2.imwrite(\"depth.png\", cv2.rotate(depthMap, cv2.ROTATE_90_CLOCKWISE))"
   ]
  },
  {
   "source": [
    "### Compute point cloud"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointSubsample = 24\n",
    "voxelSize = 100\n",
    "voxelStopFraction = 10\n",
    "occupancyThreshold = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Points in unfiltered pointcloud: 9600; completed in 0.00264 sec\n"
     ]
    }
   ],
   "source": [
    "timeKeeper.startPerfCounter()\n",
    "\n",
    "def generatePointCloud(disparityMapL, dispToDepthMatrix):\n",
    "    points = cv2.reprojectImageTo3D(\\\n",
    "            disparityMapL, \\\n",
    "            dispToDepthMatrix)\n",
    "\n",
    "    # Reshaping to a list of 3D coordinates\n",
    "    pointCloud = points.reshape(\\\n",
    "                (points.shape[0]*points.shape[1],3))[0::pointSubsample]\\\n",
    "                                                .astype(np.int16)\n",
    "\n",
    "    return pointCloud\n",
    "\n",
    "pointCloud = generatePointCloud(stereoMatcher.disparityMapL,\\\n",
    "                                imageProcessor.dispToDepthMatrix)\n",
    "\n",
    "print(\"\".join([\"Points in unfiltered pointcloud: {}; \",\\\n",
    "                    \"completed in {:.5f} sec\"]).format(\\\n",
    "                    pointCloud.shape[0], \\\n",
    "                    timeKeeper.returnPerfCounter()))"
   ]
  },
  {
   "source": [
    "Filtering extreme points"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Points in filtered pointcloud: 8006; completed in 0.00086 sec\n"
     ]
    }
   ],
   "source": [
    "timeKeeper.startPerfCounter()\n",
    "\n",
    "def filterPointCloud(pointCloud):\n",
    "    # Filtering x values\n",
    "    pointCloud = pointCloud[np.logical_and(\\\n",
    "            pointCloud[:, 0]>pointCloud[:, 0].min(), \\\n",
    "            pointCloud[:, 0]<pointCloud[:, 0].max())]\n",
    "    # Filtering y values\n",
    "    pointCloud = pointCloud[np.logical_and(\\\n",
    "            pointCloud[:, 1]>pointCloud[:, 1].min(), \\\n",
    "            pointCloud[:, 1]<pointCloud[:, 1].max())]\n",
    "    # Filtering z values\n",
    "    pointCloud = pointCloud[np.logical_and(\\\n",
    "            pointCloud[:, 2]>pointCloud[:, 2].min(), \\\n",
    "            pointCloud[:, 2]<pointCloud[:, 2].max())]\n",
    "\n",
    "    return pointCloud\n",
    "\n",
    "pointCloud = filterPointCloud(pointCloud)\n",
    "\n",
    "print(\"\".join([\"Points in filtered pointcloud: {}; \",\\\n",
    "                \"completed in {:.5f} sec\"]).format(\\\n",
    "                pointCloud.shape[0], \\\n",
    "                timeKeeper.returnPerfCounter()))"
   ]
  },
  {
   "source": [
    "Rotate point cloud to have y forward"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "redefineRotationMatrix = np.array([ [ 0,  0, -1],\n",
    "                                    [ 0,  1,  0],\n",
    "                                    [ 1,  0,  0] ])\n",
    "\n",
    "def rotatePointCloud(pointCloud, rotationMatrix):\n",
    "    pointCloud = np.dot(pointCloud[:], rotationMatrix)\n",
    "\n",
    "    return pointCloud\n",
    "\n",
    "pointCloud = rotatePointCloud(pointCloud, redefineRotationMatrix)"
   ]
  },
  {
   "source": [
    "### View point cloud"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "495d666de7f444c0a4bc8fa23e33bf6b"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "def plotGrid(grid, s):\n",
    "    fig = plt.figure(figsize=(7,7))\n",
    "    ax = fig.add_subplot(111, projection = \"3d\")\n",
    "\n",
    "    ax.scatter(grid[:,0], grid[:,1], grid[:,2], s=s)\n",
    "    ax.set_xlabel(\"$x$\")\n",
    "    ax.set_ylabel(\"$y$\")\n",
    "    ax.set_zlabel(\"$z$\")\n",
    "\n",
    "    # Camera axis begins at x=0 and looks to positive x\n",
    "    ax.set_xlim(0,2000)\n",
    "    ax.set_ylim(-1000,1000)\n",
    "    ax.set_zlim(-1000,1000)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plotGrid(pointCloud, 1)"
   ]
  },
  {
   "source": [
    "### Voxelize point cloud"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Voxels in grid: 65; completed in 0.00868 sec; 70 iterations\n"
     ]
    }
   ],
   "source": [
    "voxelGrid = None\n",
    "\n",
    "timeKeeper.startPerfCounter()\n",
    "\n",
    "def voxelizePointCloud(pointCloud, voxelSize, \\\n",
    "                        occupancyThreshold, voxelStopFraction):\n",
    "    iterations = 0\n",
    "    voxelGrid = []\n",
    "    initialSize = pointCloud.shape[0]\n",
    "    remainingPoints = initialSize\n",
    "    samplingLimit = np.zeros_like(pointCloud[0])\n",
    "        \n",
    "    while remainingPoints>(initialSize/voxelStopFraction):\n",
    "\n",
    "        sampledPoint = pointCloud[np.random.randint(0,remainingPoints)]\n",
    "\n",
    "        for n in range(3):\n",
    "            samplingLimit[n]=\\\n",
    "                (sampledPoint[n]//voxelSize)*voxelSize\n",
    "\n",
    "        mask = np.ones(remainingPoints, dtype=bool)\n",
    "\n",
    "        for n in range(len(sampledPoint)):\n",
    "            mask = np.logical_and(mask, np.logical_and(\\\n",
    "                pointCloud[:,n]>=samplingLimit[n], \\\n",
    "                pointCloud[:,n]<samplingLimit[n]+voxelSize))\n",
    "\n",
    "        pointsInVoxel = pointCloud[mask]\n",
    "\n",
    "        if len(pointsInVoxel)>occupancyThreshold:\n",
    "            voxelMidpoint = samplingLimit+voxelSize/2\n",
    "            voxelGrid.append(voxelMidpoint)\n",
    "\n",
    "        pointCloud = pointCloud[np.invert(mask)]\n",
    "\n",
    "        iterations+=1\n",
    "\n",
    "        remainingPoints = pointCloud.shape[0]\n",
    "\n",
    "    voxelGrid = np.array(voxelGrid, dtype=np.int16)\n",
    "\n",
    "    ### These steps will potentially need to be changed\n",
    "\n",
    "    if voxelGrid is None:\n",
    "        voxelGrid = voxelGrid\n",
    "\n",
    "    else:\n",
    "        voxelGrid = np.unique(np.vstack((voxelGrid, voxelGrid)), axis=0)\n",
    "\n",
    "    ###\n",
    "\n",
    "    return voxelGrid, iterations\n",
    "\n",
    "voxelGrid, iterations = voxelizePointCloud(pointCloud, voxelSize, \\\n",
    "                        occupancyThreshold, voxelStopFraction)\n",
    "\n",
    "print(\"\".join([\"Voxels in grid: {}; \",\\\n",
    "                \"completed in {:.5f} sec; {} iterations\"]).format(\\\n",
    "                voxelGrid.shape[0], \\\n",
    "                timeKeeper.returnPerfCounter(), \\\n",
    "                iterations))"
   ]
  },
  {
   "source": [
    "### View voxelized point cloud"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "91d58c9fb60441ba9c0d61c5f9538f93"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "plotGrid(voxelGrid, 100)"
   ]
  },
  {
   "source": [
    "### Refine voxel grid with newer data\n",
    "\n",
    "Interchanging data from calibration since calibration was \n",
    "done vertically\n",
    "\n",
    "The x y notations are in image coordinates"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Horizontal: 24.915932084055157\nVertical: 14.867033874651561\n"
     ]
    }
   ],
   "source": [
    "# Horizontal field of view (degrees)\n",
    "fovH = ((imageProcessor.fovYL+imageProcessor.fovYR)/4)*np.pi/180\n",
    "fovH -= fovH/8\n",
    "print(\"Horizontal:\", fovH*180/np.pi)\n",
    "\n",
    "# Vertical field of view (degrees)\n",
    "fovV = ((imageProcessor.fovXL+imageProcessor.fovXR)/4)*np.pi/180\n",
    "fovV -= fovV/8\n",
    "print(\"Vertical:\", fovV*180/np.pi)"
   ]
  },
  {
   "source": [
    "### Checking for voxels in range\n",
    "\n",
    "The refinement is done by simply replacing the older voxels in view of the camera in the base grid with the new voxels.\n",
    "\n",
    "Here the voxels that may potentially be affected are found."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(65,)\n(65, 3)\n(65, 3)\n[[550, -650, -250], [1250, 250, 250]]\n"
     ]
    }
   ],
   "source": [
    "# Do this after compensations for atleast camera translation have been made\n",
    "# Performed on the base voxel grid\n",
    "# Distances to every voxel in base grid from camera\n",
    "\n",
    "# Offset camera position with distance from robot center and distance of robot \n",
    "# from origin\n",
    "# The top or left camera is taken to represent the whole camera grid\n",
    "cameraPosition = np.zeros([3])\n",
    "distanceToVoxels = np.linalg.norm(voxelGrid-cameraPosition, axis=1)\n",
    "print(distanceToVoxels.shape)\n",
    "\n",
    "# Distance within which points may be modified\n",
    "distanceToCheck = 1500\n",
    "\n",
    "# These are the points to check\n",
    "# Performed on the base voxel grid\n",
    "voxelsWithinRange = voxelGrid[distanceToVoxels<=distanceToCheck]\n",
    "print(voxelGrid.shape)\n",
    "print(voxelsWithinRange.shape)\n",
    "\n",
    "# Checking bounds on the coordinate axes\n",
    "# Performed on the base voxel grid\n",
    "voxelCheckBound = [[voxelsWithinRange[:,0].min(), voxelsWithinRange[:,1].min(), \\\n",
    "                        voxelsWithinRange[:,2].min()], \\\n",
    "                    [voxelsWithinRange[:,0].max(), voxelsWithinRange[:,1].max(), \\\n",
    "                        voxelsWithinRange[:,2].max()]]\n",
    "print(voxelCheckBound) # min, max"
   ]
  },
  {
   "source": [
    "### Generating new voxel grid from newer data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-574e86bfbcbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load next image pair\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimageL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimageR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadImages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageSelection\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Undistort images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimageProcessor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvertToGrayscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimageR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-dc69c90d8c6e>\u001b[0m in \u001b[0;36mloadImages\u001b[1;34m(imageNumber)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mloadImages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageNumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mimageL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageGlobL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimageNumber\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mimageR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageGlobR\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimageNumber\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Load next image pair\n",
    "imageL, imageR = loadImages(imageSelection[1])\n",
    "\n",
    "# Undistort images\n",
    "imageProcessor.convertToGrayscale(imageL, imageR)\n",
    "imageProcessor.undistortRectifyRemap(imageProcessor.grayImageL, \\\n",
    "                                        imageProcessor.grayImageR)\n",
    "\n",
    "# Compute disparity map\n",
    "stereoMatcher.computeDisparity(\\\n",
    "                grayImageL=imageProcessor.undistortImageL, \\\n",
    "                grayImageR=imageProcessor.undistortImageR)\n",
    "\n",
    "stereoMatcher.clampDisparity()\n",
    "stereoMatcher.applyClosingFilter()\n",
    "\n",
    "# Compute new point cloud\n",
    "pointCloud = generatePointCloud(stereoMatcher.disparityMapL,\\\n",
    "                                imageProcessor.dispToDepthMatrix)\n",
    "\n",
    "# Filter point cloud\n",
    "pointCloud = filterPointCloud(pointCloud)\n",
    "\n",
    "# Rotate point cloud\n",
    "pointCloud = rotatePointCloud(pointCloud, redefineRotationMatrix)\n",
    "\n",
    "# Generate new voxel grid\n",
    "newVoxelGrid, iterations = voxelizePointCloud(pointCloud, voxelSize, \\\n",
    "                        occupancyThreshold, voxelStopFraction)"
   ]
  },
  {
   "source": [
    "### View new voxel grid"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c8a7304b1a8f4a36a5bf66fa560e077a"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "plotGrid(newVoxelGrid, 100)"
   ]
  },
  {
   "source": [
    "### Angle ranges of rotated new voxel grid (Exploration only)\n",
    "\n",
    "Could potentially be found from the rotation matrix and be offset \n",
    "by the camera fovs.\n",
    "\n",
    "Computing yaws on the new voxel grid; xy plane. A line along x axis has 0 degrees of yaw.\n",
    "\n",
    "Normally this would be the results of the latest iteration after \n",
    "they are rotated and translated.\n",
    "\n",
    "Taking x forward"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(61,)\n[ 24.443953 -27.47443 ]\n51.918385239909625\n"
     ]
    }
   ],
   "source": [
    "yawToNewVoxels = np.arctan2(newVoxelGrid[:,1], newVoxelGrid[:,0]) # y, x\n",
    "print(yawToNewVoxels.shape)\n",
    "\n",
    "yawCheckBound = np.array([yawToNewVoxels.max(), yawToNewVoxels.min()]) # left, right\n",
    "print(yawCheckBound*180/np.pi)\n",
    "print((yawCheckBound[0]-yawCheckBound[1])*180/np.pi)\n",
    "\n",
    "#print(yawToNewVoxels*180/np.pi)"
   ]
  },
  {
   "source": [
    "Computing pitches on the new voxel grid; xz plane.\n",
    "\n",
    "Taking x forward"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(61,)\n[ 15.255118 -16.38954 ]\n31.64465916054635\n"
     ]
    }
   ],
   "source": [
    "pitchToNewVoxels = np.arctan2(newVoxelGrid[:,2], newVoxelGrid[:,0])\n",
    "print(pitchToNewVoxels.shape)\n",
    "\n",
    "                                                                # up, down\n",
    "pitchCheckBound = np.array([pitchToNewVoxels.max(), pitchToNewVoxels.min()]) \n",
    "print(pitchCheckBound*180/np.pi)\n",
    "print((pitchCheckBound[0]-pitchCheckBound[1])*180/np.pi)\n",
    "\n",
    "#print(pitchToNewVoxels*180/np.pi)"
   ]
  },
  {
   "source": [
    "Computing rolls on the new voxel grid; yz plane.\n",
    "\n",
    "Taking x forward"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(61,)\n[ 171.86989 -174.80557]\n346.67548573975506\n"
     ]
    }
   ],
   "source": [
    "rollToNewVoxels = np.arctan2(newVoxelGrid[:,2], newVoxelGrid[:,1])\n",
    "print(rollToNewVoxels.shape)\n",
    "\n",
    "rollCheckBound = np.array([rollToNewVoxels.max(), rollToNewVoxels.min()])\n",
    "print(rollCheckBound*180/np.pi)\n",
    "print((rollCheckBound[0]-rollCheckBound[1])*180/np.pi)\n",
    "\n",
    "#print(rollToNewVoxels*180/np.pi)"
   ]
  },
  {
   "source": [
    "From the results above, checking for pitch and roll will return \n",
    "inconclusive results unless the rotation is in an exact side profile of the\n",
    "grid.\n",
    "\n",
    "This can be mitigated by doing the check before rotating or translating, but that would require the base grid to be rotated as a whole, refined, and then re-rotated back.\n",
    "\n",
    "To save on computation, the yaw range for the new voxel grid may simply be taken from camera properties already found during calibration. \n",
    "\n",
    "Then, to check where the camera is facing, a vector of unit distance from the camera facing along its axis could be rotated and translated along with the camera. \n",
    "\n",
    "Its yaw with respect to the camera center can then be calculated, and then offset by half its horizontal fov on both sides, to find the yaw limits within which the base voxels may be modified."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Finding yaw of camera and voxels within range\n",
    "Finding yaw of camera"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[  0   0 100]\n",
      "[100   0   0]\n",
      "0.0\n",
      "[ 0.43486505 -0.43486505]\n",
      "[ 24.91593208 -24.91593208]\n",
      "[ 0.43486505 -0.43486505]\n",
      "[ 24.91593208 -24.91593208]\n"
     ]
    }
   ],
   "source": [
    "# Camera vector before rotation, z forward\n",
    "cameraDirectionVector = np.array([0,0,100])\n",
    "print(cameraDirectionVector)\n",
    "\n",
    "# Camera vector after rotation (do not translate)\n",
    "# Also perform rotations to align with the robot frame, not done here\n",
    "cameraDirectionVector = np.dot(\\\n",
    "            cameraDirectionVector, redefineRotationMatrix)\n",
    "print(cameraDirectionVector)\n",
    "\n",
    "# Finding yaw of the camera vector (again, assuming no translation)\n",
    "cameraYaw = np.arctan2(cameraDirectionVector[1], cameraDirectionVector[0])\n",
    "print(cameraYaw*180/np.pi)\n",
    "\n",
    "cameraYawRange = np.array([cameraYaw+fovH, cameraYaw-fovH])\n",
    "print(cameraYawRange*180/np.pi)\n",
    "\n",
    "# Wrapping around values at -180, 180 degrees\n",
    "for n in range(len(cameraYawRange)):\n",
    "    if cameraYawRange[n]>np.pi:\n",
    "        cameraYawRange[n] -= 2*np.pi\n",
    "    if cameraYawRange[n]<=-np.pi:\n",
    "        cameraYawRange[n] += 2*np.pi\n",
    "\n",
    "cameraYawRange = np.sort(cameraYawRange)[::-1]\n",
    "\n",
    "print(cameraYawRange*180/np.pi)"
   ]
  },
  {
   "source": [
    "Finding yaw of voxels within range"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60, 3)\n(60,)\n"
     ]
    }
   ],
   "source": [
    "# Shifting the voxels around the camera to origin so that yaw to each voxel \n",
    "# can be found\n",
    "translatedVoxelsWithinRange = voxelsWithinRange-cameraPosition\n",
    "print(translatedVoxelsWithinRange.shape)\n",
    "\n",
    "yawToTranslatedVoxels = np.arctan2(translatedVoxelsWithinRange[:,1], \\\n",
    "                                translatedVoxelsWithinRange[:,0])\n",
    "print(yawToTranslatedVoxels.shape)\n",
    "#print(yawToTranslatedVoxels*180/np.pi)"
   ]
  },
  {
   "source": [
    "Finding voxels that need to be removed"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(58, 3)\n"
     ]
    }
   ],
   "source": [
    "if cameraYawRange[0]>np.pi/2 and cameraYawRange[1]<-np.pi/2:\n",
    "    voxelsToRemove = voxelsWithinRange[np.logical_and(\\\n",
    "        yawToTranslatedVoxels[:]>cameraYawRange[0], \\\n",
    "        yawToTranslatedVoxels[:]<cameraYawRange[1]\n",
    "        )]\n",
    "else:\n",
    "    voxelsToRemove = voxelsWithinRange[np.logical_and(\\\n",
    "        yawToTranslatedVoxels[:]<cameraYawRange[0], \\\n",
    "        yawToTranslatedVoxels[:]>cameraYawRange[1]\n",
    "        )]\n",
    "\n",
    "print(voxelsToRemove.shape)"
   ]
  },
  {
   "source": [
    "The voxels to be removed are then removed from the base grid"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(61, 3)\n",
      "(58, 3)\n",
      "(3, 3)\n",
      "[[1150 -550  -50]\n",
      " [1250 -650  250]\n",
      " [1350 -650  250]]\n"
     ]
    }
   ],
   "source": [
    "print(voxelGrid.shape)\n",
    "print(voxelsToRemove.shape)\n",
    "\n",
    "# Found this online\n",
    "def in1d_dot_approach(A,B):\n",
    "    \"\"\"Returns the first array with elements from the second array removed\"\"\"\n",
    "    cumdims = (np.maximum(A.max(),B.max())+1)**np.arange(B.shape[1])\n",
    "    return A[~np.in1d(A.dot(cumdims),B.dot(cumdims))]\n",
    "\n",
    "voxelRemovedGrid = in1d_dot_approach(voxelGrid, voxelsToRemove)\n",
    "print(voxelRemovedGrid.shape)\n",
    "print(voxelRemovedGrid)"
   ]
  },
  {
   "source": [
    "Combining unique voxels from voxel-removed base grid and the new voxel grid to get the updated grid"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(61, 3)\n(61, 3)\n"
     ]
    }
   ],
   "source": [
    "updatedVoxelGrid = np.unique(\\\n",
    "                    np.vstack((voxelRemovedGrid, newVoxelGrid)), axis=0)\n",
    "print(updatedVoxelGrid.shape)\n",
    "voxelGrid = updatedVoxelGrid\n",
    "print(voxelGrid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}