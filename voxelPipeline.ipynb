{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python368jvsc74a57bd01b74fdc6a0069e63d7c35520416cfe241b2e1d296eedc56ee9c4fe2929446925",
   "display_name": "Python 3.6.8 64-bit ('bot': venv)",
   "language": "python"
  },
  "metadata": {
   "interpreter": {
    "hash": "1b74fdc6a0069e63d7c35520416cfe241b2e1d296eedc56ee9c4fe2929446925"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Voxel pipeline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Import requirements"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from ImageProcessor import ImageProcessor\n",
    "from StereoMatcher import StereoMatcher\n",
    "from helperScripts.TimeKeeper import TimeKeeper\n",
    "from VoxelGrid import VoxelGrid\n",
    "\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "source": [
    "### Load calibrations and other data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading from data/monoCalibration.json\nLoaded mono calibration\nReading from data/stereoCalibration.json\nLoaded stereo calibration\nReading from data/cameraProperties.json\nLoaded camera properties\nReading from data/stereoRectify.json\nLoaded stereo rectification data\n"
     ]
    }
   ],
   "source": [
    "imageProcessor = ImageProcessor()\n",
    "imageProcessor.verbose = True\n",
    "imageProcessor.loadMonoCalibration()\n",
    "imageProcessor.loadStereoCalibration()\n",
    "imageProcessor.loadCameraProperties()\n",
    "imageProcessor.loadStereoRectify()"
   ]
  },
  {
   "source": [
    "### Create stereo matcher"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading from data/parametersSGBM.json\n"
     ]
    }
   ],
   "source": [
    "stereoMatcher = StereoMatcher(imageProcessor=imageProcessor, \\\n",
    "                matcher=\"SGBM\", vertical=True, createRightMatcher=False)\n",
    "\n",
    "imageProcessor.initUndistortRectifyMap()\n",
    "#stereoMatcher.createDisparityWLSFilter()"
   ]
  },
  {
   "source": [
    "### Timekeeper for performance metrics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeKeeper = TimeKeeper()"
   ]
  },
  {
   "source": [
    "### Loading images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Selections: 0-1\n"
     ]
    }
   ],
   "source": [
    "path = \"testImages/voxelTestImages\"\n",
    "imageGlobL = sorted(glob.glob(\"\".join([path, \"/top_*\", \".png\"])))\n",
    "imageGlobR = sorted(glob.glob(\"\".join([path, \"/bottom_*\", \".png\"])))\n",
    "print (\"Selections: 0-{}\".format(len(imageGlobL)-1))"
   ]
  },
  {
   "source": [
    "### Select image pair and display"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7650233946ae477596d5aaf932446ad4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23c7dcb2da0>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "imageStart = 0\n",
    "imageSelection = [imageStart, imageStart+1]\n",
    "\n",
    "def loadImages(imageNumber):\n",
    "    imageL = cv2.imread(imageGlobL[imageNumber])\n",
    "    imageR = cv2.imread(imageGlobR[imageNumber])\n",
    "\n",
    "    return imageL, imageR\n",
    "\n",
    "imageL, imageR = loadImages(imageSelection[0])\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(np.hstack([imageL, imageR]), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "source": [
    "### Convert to grayscale and undistort"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageProcessor.convertToGrayscale(imageL, imageR)\n",
    "imageProcessor.undistortRectifyRemap(imageProcessor.grayImageL, \\\n",
    "                                        imageProcessor.grayImageR)"
   ]
  },
  {
   "source": [
    "### View undistorted image"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "10ae0482a1144a72a2bd90dad211de0b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23c7ddb0b70>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle(\"left/right undistorted\")\n",
    "plt.imshow(cv2.cvtColor(np.hstack([imageProcessor.undistortImageL, \\\n",
    "            imageProcessor.undistortImageR]), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "87ca9a4454254398bfdbd3b5e81e9b89"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23c7e71cc88>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle(\"horizontal epipolar\")\n",
    "plt.imshow(cv2.cvtColor(imageProcessor.drawHorEpipolarLines(\\\n",
    "        imageProcessor.undistortImageL, imageProcessor.undistortImageR), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e50a2b0317b04143a26ff03d489375d2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23c7ecd97b8>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(6,15))\n",
    "fig.suptitle(\"left/right undistorted\")\n",
    "plt.imshow(cv2.cvtColor(imageProcessor.drawVertEpipolarLines(\\\n",
    "        imageProcessor.undistortImageL, imageProcessor.undistortImageR), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "source": [
    "### Compute disparity map"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "minDisparity: 9.0\nmaxDisparity: 40.0\n"
     ]
    }
   ],
   "source": [
    "stereoMatcher.computeDisparity(\\\n",
    "                grayImageL=imageProcessor.undistortImageL, \\\n",
    "                grayImageR=imageProcessor.undistortImageR)\n",
    "\n",
    "stereoMatcher.clampDisparity()\n",
    "stereoMatcher.applyClosingFilter()\n",
    "#stereoMatcher.applyWLSFilterDisparity()\n",
    "\n",
    "print (\"minDisparity:\", stereoMatcher.disparityMapL.min())\n",
    "print (\"maxDisparity:\", stereoMatcher.disparityMapL.max())"
   ]
  },
  {
   "source": [
    "### View disparity map"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be209f9abfba4a0aba4e505869df9bdd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23c7eb9ebe0>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(cv2.rotate(stereoMatcher.disparityMapL, \\\n",
    "    cv2.ROTATE_90_CLOCKWISE))"
   ]
  },
  {
   "source": [
    "### Compute depth map"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9.0\n40.0\n(640, 360)\n493.3714\n2192.7617\n"
     ]
    }
   ],
   "source": [
    "focalLength = imageProcessor.projectionMatrixL[0][0] # changes with rectify?\n",
    "baseline = 32 # mm, measured irl\n",
    "\n",
    "stereoMatcher.disparityMapL[stereoMatcher.disparityMapL==0] = 0.9\n",
    "stereoMatcher.disparityMapL[stereoMatcher.disparityMapL==-1] = 0.9\n",
    "\n",
    "depthMap = np.empty_like(stereoMatcher.disparityMapL)\n",
    "depthMap = (focalLength*baseline)/stereoMatcher.disparityMapL[:]\n",
    "\n",
    "print (stereoMatcher.disparityMapL.min())\n",
    "print (stereoMatcher.disparityMapL.max())\n",
    "print (depthMap.shape)\n",
    "print (depthMap.min())\n",
    "print (depthMap.max())"
   ]
  },
  {
   "source": [
    "### View depth map"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "281ddecb4e1d42f697fcf417f70821a9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23c7ec19a90>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(cv2.rotate(depthMap, cv2.ROTATE_90_CLOCKWISE))"
   ]
  },
  {
   "source": [
    "### Compute point cloud"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointSubsample = 24\n",
    "voxelSize = 100\n",
    "voxelStopFraction = 10\n",
    "occupancyThreshold = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Points in unfiltered pointcloud: 9600; completed in 0.00264 sec\n"
     ]
    }
   ],
   "source": [
    "timeKeeper.startPerfCounter()\n",
    "\n",
    "def generatePointCloud(disparityMapL, dispToDepthMatrix):\n",
    "    points = cv2.reprojectImageTo3D(\\\n",
    "            disparityMapL, \\\n",
    "            dispToDepthMatrix)\n",
    "\n",
    "    # Reshaping to a list of 3D coordinates\n",
    "    pointCloud = points.reshape(\\\n",
    "                (points.shape[0]*points.shape[1],3))[0::pointSubsample]\\\n",
    "                                                .astype(np.int16)\n",
    "\n",
    "    return pointCloud\n",
    "\n",
    "pointCloud = generatePointCloud(stereoMatcher.disparityMapL,\\\n",
    "                                imageProcessor.dispToDepthMatrix)\n",
    "\n",
    "print(\"\".join([\"Points in unfiltered pointcloud: {}; \",\\\n",
    "                    \"completed in {:.5f} sec\"]).format(\\\n",
    "                    pointCloud.shape[0], \\\n",
    "                    timeKeeper.returnPerfCounter()))"
   ]
  },
  {
   "source": [
    "Filtering extreme points"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Points in filtered pointcloud: 7542; completed in 0.00097 sec\n"
     ]
    }
   ],
   "source": [
    "timeKeeper.startPerfCounter()\n",
    "\n",
    "def filterPointCloud(pointCloud):\n",
    "    # Filtering x values\n",
    "    pointCloud = pointCloud[np.logical_and(\\\n",
    "            pointCloud[:, 0]>pointCloud[:, 0].min(), \\\n",
    "            pointCloud[:, 0]<pointCloud[:, 0].max())]\n",
    "    # Filtering y values\n",
    "    pointCloud = pointCloud[np.logical_and(\\\n",
    "            pointCloud[:, 1]>pointCloud[:, 1].min(), \\\n",
    "            pointCloud[:, 1]<pointCloud[:, 1].max())]\n",
    "    # Filtering z values\n",
    "    pointCloud = pointCloud[np.logical_and(\\\n",
    "            pointCloud[:, 2]>pointCloud[:, 2].min(), \\\n",
    "            pointCloud[:, 2]<pointCloud[:, 2].max())]\n",
    "\n",
    "    return pointCloud\n",
    "\n",
    "pointCloud = filterPointCloud(pointCloud)\n",
    "\n",
    "print(\"\".join([\"Points in filtered pointcloud: {}; \",\\\n",
    "                \"completed in {:.5f} sec\"]).format(\\\n",
    "                pointCloud.shape[0], \\\n",
    "                timeKeeper.returnPerfCounter()))"
   ]
  },
  {
   "source": [
    "Rotate point cloud to have y forward"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "redefineRotationMatrix = np.array([ [ 0,  0, -1],\n",
    "                                    [ 0,  1,  0],\n",
    "                                    [ 1,  0,  0] ])\n",
    "\n",
    "def rotatePointCloud(pointCloud, rotationMatrix):\n",
    "    pointCloud = np.dot(pointCloud[:], rotationMatrix)\n",
    "\n",
    "    return pointCloud\n",
    "\n",
    "pointCloud = rotatePointCloud(pointCloud, redefineRotationMatrix)"
   ]
  },
  {
   "source": [
    "### View point cloud"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7b9e384c54cd4a0d8d970e934bc471bf"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "def plotGrid(grid, s):\n",
    "    fig = plt.figure(figsize=(7,7))\n",
    "    ax = fig.add_subplot(111, projection = \"3d\")\n",
    "\n",
    "    ax.scatter(grid[:,0], grid[:,1], grid[:,2], s=s)\n",
    "    ax.set_xlabel(\"$x$\")\n",
    "    ax.set_ylabel(\"$y$\")\n",
    "    ax.set_zlabel(\"$z$\")\n",
    "\n",
    "    # Camera axis begins at x=0 and looks to positive x\n",
    "    ax.set_xlim(0,2000)\n",
    "    ax.set_ylim(-1000,1000)\n",
    "    ax.set_zlim(-1000,1000)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plotGrid(pointCloud, 1)"
   ]
  },
  {
   "source": [
    "### Voxelize point cloud"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Voxels in grid: 128; completed in 0.01690 sec; 160 iterations\n"
     ]
    }
   ],
   "source": [
    "voxelGrid = None\n",
    "\n",
    "timeKeeper.startPerfCounter()\n",
    "\n",
    "def voxelizePointCloud(pointCloud, voxelSize, \\\n",
    "                        occupancyThreshold, voxelStopFraction):\n",
    "    iterations = 0\n",
    "    voxelGrid = []\n",
    "    initialSize = pointCloud.shape[0]\n",
    "    remainingPoints = initialSize\n",
    "    samplingLimit = np.zeros_like(pointCloud[0])\n",
    "        \n",
    "    while remainingPoints>(initialSize/voxelStopFraction):\n",
    "\n",
    "        sampledPoint = pointCloud[np.random.randint(0,remainingPoints)]\n",
    "\n",
    "        for n in range(3):\n",
    "            samplingLimit[n]=\\\n",
    "                (sampledPoint[n]//voxelSize)*voxelSize\n",
    "\n",
    "        mask = np.ones(remainingPoints, dtype=bool)\n",
    "\n",
    "        for n in range(len(sampledPoint)):\n",
    "            mask = np.logical_and(mask, np.logical_and(\\\n",
    "                pointCloud[:,n]>=samplingLimit[n], \\\n",
    "                pointCloud[:,n]<samplingLimit[n]+voxelSize))\n",
    "\n",
    "        pointsInVoxel = pointCloud[mask]\n",
    "\n",
    "        if len(pointsInVoxel)>occupancyThreshold:\n",
    "            voxelMidpoint = samplingLimit+voxelSize/2\n",
    "            voxelGrid.append(voxelMidpoint)\n",
    "\n",
    "        pointCloud = pointCloud[np.invert(mask)]\n",
    "\n",
    "        iterations+=1\n",
    "\n",
    "        remainingPoints = pointCloud.shape[0]\n",
    "\n",
    "    voxelGrid = np.array(voxelGrid, dtype=np.int16)\n",
    "\n",
    "    ### These steps will potentially need to be changed\n",
    "\n",
    "    if voxelGrid is None:\n",
    "        voxelGrid = voxelGrid\n",
    "\n",
    "    else:\n",
    "        voxelGrid = np.unique(np.vstack((voxelGrid, voxelGrid)), axis=0)\n",
    "\n",
    "    ###\n",
    "\n",
    "    return voxelGrid, iterations\n",
    "\n",
    "voxelGrid, iterations = voxelizePointCloud(pointCloud, voxelSize, \\\n",
    "                        occupancyThreshold, voxelStopFraction)\n",
    "\n",
    "print(\"\".join([\"Voxels in grid: {}; \",\\\n",
    "                \"completed in {:.5f} sec; {} iterations\"]).format(\\\n",
    "                voxelGrid.shape[0], \\\n",
    "                timeKeeper.returnPerfCounter(), \\\n",
    "                iterations))"
   ]
  },
  {
   "source": [
    "### View voxelized point cloud"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c954b502e7294f16aaeb683020180bf3"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "plotGrid(voxelGrid, voxelSize)"
   ]
  },
  {
   "source": [
    "### Refine voxel grid with newer data\n",
    "\n",
    "Interchanging data from calibration since calibration was \n",
    "done vertically\n",
    "\n",
    "The x y notations are in image coordinates"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Horizontal: 24.915932084055157\nVertical: 14.867033874651561\n"
     ]
    }
   ],
   "source": [
    "# Horizontal field of view (degrees)\n",
    "fovH = ((imageProcessor.fovYL+imageProcessor.fovYR)/4)*np.pi/180\n",
    "fovH -= fovH/8\n",
    "print(\"Horizontal:\", fovH*180/np.pi)\n",
    "\n",
    "# Vertical field of view (degrees)\n",
    "fovV = ((imageProcessor.fovXL+imageProcessor.fovXR)/4)*np.pi/180\n",
    "fovV -= fovV/8\n",
    "print(\"Vertical:\", fovV*180/np.pi)"
   ]
  },
  {
   "source": [
    "### Checking for voxels in range\n",
    "\n",
    "The refinement is done by simply replacing the older voxels in view of the camera in the base grid with the new voxels.\n",
    "\n",
    "Here the voxels that may potentially be affected are found."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(128,)\n(128, 3)\n(124, 3)\n[[550, -450, -350], [1350, 450, 350]]\n"
     ]
    }
   ],
   "source": [
    "# Do this after compensations for atleast camera translation have been made\n",
    "# Performed on the base voxel grid\n",
    "# Distances to every voxel in base grid from camera\n",
    "\n",
    "# Offset camera position with distance from robot center and distance of robot \n",
    "# from origin\n",
    "# The top or left camera is taken to represent the whole camera grid\n",
    "cameraPosition = np.zeros([3])\n",
    "distanceToVoxels = np.linalg.norm(voxelGrid-cameraPosition, axis=1)\n",
    "print(distanceToVoxels.shape)\n",
    "\n",
    "# Distance within which points may be modified\n",
    "distanceToCheck = 1500\n",
    "\n",
    "# These are the points to check\n",
    "# Performed on the base voxel grid\n",
    "voxelsWithinRange = voxelGrid[distanceToVoxels<=distanceToCheck]\n",
    "print(voxelGrid.shape)\n",
    "print(voxelsWithinRange.shape)\n",
    "\n",
    "# Checking bounds on the coordinate axes\n",
    "# Performed on the base voxel grid\n",
    "voxelCheckBound = [[voxelsWithinRange[:,0].min(), voxelsWithinRange[:,1].min(), \\\n",
    "                        voxelsWithinRange[:,2].min()], \\\n",
    "                    [voxelsWithinRange[:,0].max(), voxelsWithinRange[:,1].max(), \\\n",
    "                        voxelsWithinRange[:,2].max()]]\n",
    "print(voxelCheckBound) # min, max"
   ]
  },
  {
   "source": [
    "### Generating new voxel grid from newer data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "30ecf531d934492a82f42d37111bb353"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23c8a865630>"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "# Load next image pair\n",
    "imageL, imageR = loadImages(imageSelection[1])\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(np.hstack([imageL, imageR]), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Completed in 0.045322 seconds\n"
     ]
    }
   ],
   "source": [
    "timeKeeper.startPerfCounter()\n",
    "\n",
    "# Undistort images\n",
    "imageProcessor.convertToGrayscale(imageL, imageR)\n",
    "imageProcessor.undistortRectifyRemap(imageProcessor.grayImageL, \\\n",
    "                                        imageProcessor.grayImageR)\n",
    "\n",
    "# Compute disparity map\n",
    "stereoMatcher.computeDisparity(\\\n",
    "                grayImageL=imageProcessor.undistortImageL, \\\n",
    "                grayImageR=imageProcessor.undistortImageR)\n",
    "\n",
    "stereoMatcher.clampDisparity()\n",
    "stereoMatcher.applyClosingFilter()\n",
    "\n",
    "# Compute new point cloud\n",
    "pointCloud = generatePointCloud(stereoMatcher.disparityMapL,\\\n",
    "                                imageProcessor.dispToDepthMatrix)\n",
    "\n",
    "# Filter point cloud\n",
    "pointCloud = filterPointCloud(pointCloud)\n",
    "\n",
    "# Rotate point cloud\n",
    "pointCloud = rotatePointCloud(pointCloud, redefineRotationMatrix)\n",
    "\n",
    "# Generate new voxel grid\n",
    "newVoxelGrid, iterations = voxelizePointCloud(pointCloud, voxelSize, \\\n",
    "                        occupancyThreshold, voxelStopFraction)\n",
    "\n",
    "timeKeeper.printPerfCounter()"
   ]
  },
  {
   "source": [
    "### View new voxel grid"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b63306c27c6542799b61cc6888d432fe"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "plotGrid(newVoxelGrid, voxelSize)"
   ]
  },
  {
   "source": [
    "### Angle ranges of rotated new voxel grid (Exploration only)\n",
    "\n",
    "Could potentially be found from the rotation matrix and be offset \n",
    "by the camera fovs.\n",
    "\n",
    "Computing yaws on the new voxel grid; xy plane. A line along x axis has 0 degrees of yaw.\n",
    "\n",
    "Normally this would be the results of the latest iteration after \n",
    "they are rotated and translated.\n",
    "\n",
    "Taking x forward"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(75,)\n[ 28.300755 -28.300755]\n56.60151127451804\n"
     ]
    }
   ],
   "source": [
    "yawToNewVoxels = np.arctan2(newVoxelGrid[:,1], newVoxelGrid[:,0]) # y, x\n",
    "print(yawToNewVoxels.shape)\n",
    "\n",
    "yawCheckBound = np.array([yawToNewVoxels.max(), yawToNewVoxels.min()]) # left, right\n",
    "print(yawCheckBound*180/np.pi)\n",
    "print((yawCheckBound[0]-yawCheckBound[1])*180/np.pi)\n",
    "\n",
    "#print(yawToNewVoxels*180/np.pi)"
   ]
  },
  {
   "source": [
    "Computing pitches on the new voxel grid; xz plane.\n",
    "\n",
    "Taking x forward"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(75,)\n[ 16.38954 -16.38954]\n32.77908186469919\n"
     ]
    }
   ],
   "source": [
    "pitchToNewVoxels = np.arctan2(newVoxelGrid[:,2], newVoxelGrid[:,0])\n",
    "print(pitchToNewVoxels.shape)\n",
    "\n",
    "                                                                # up, down\n",
    "pitchCheckBound = np.array([pitchToNewVoxels.max(), pitchToNewVoxels.min()]) \n",
    "print(pitchCheckBound*180/np.pi)\n",
    "print((pitchCheckBound[0]-pitchCheckBound[1])*180/np.pi)\n",
    "\n",
    "#print(pitchToNewVoxels*180/np.pi)"
   ]
  },
  {
   "source": [
    "Computing rolls on the new voxel grid; yz plane.\n",
    "\n",
    "Taking x forward"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(75,)\n",
      "[ 168.69008 -173.65982]\n",
      "342.34989961762926\n"
     ]
    }
   ],
   "source": [
    "rollToNewVoxels = np.arctan2(newVoxelGrid[:,2], newVoxelGrid[:,1])\n",
    "print(rollToNewVoxels.shape)\n",
    "\n",
    "rollCheckBound = np.array([rollToNewVoxels.max(), rollToNewVoxels.min()])\n",
    "print(rollCheckBound*180/np.pi)\n",
    "print((rollCheckBound[0]-rollCheckBound[1])*180/np.pi)\n",
    "\n",
    "#print(rollToNewVoxels*180/np.pi)"
   ]
  },
  {
   "source": [
    "From the results above, checking for pitch and roll will return \n",
    "inconclusive results unless the rotation is in an exact side profile of the\n",
    "grid.\n",
    "\n",
    "This can be mitigated by doing the check before rotating or translating, but that would require the base grid to be rotated as a whole, refined, and then re-rotated back.\n",
    "\n",
    "To save on computation, the yaw range for the new voxel grid may simply be taken from camera properties already found during calibration. \n",
    "\n",
    "Then, to check where the camera is facing, a vector of unit distance from the camera facing along its axis could be rotated and translated along with the camera. \n",
    "\n",
    "Its yaw with respect to the camera center can then be calculated, and then offset by half its horizontal fov on both sides, to find the yaw limits within which the base voxels may be modified."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Finding yaw of camera and voxels within range\n",
    "Finding yaw of camera"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[  0   0 100]\n[100   0   0]\n0.0\n[ 24.91593208 -24.91593208]\n[ 24.91593208 -24.91593208]\nCompleted in 0.001101 seconds\n"
     ]
    }
   ],
   "source": [
    "timeKeeper.startPerfCounter()\n",
    "\n",
    "# Camera vector before rotation, z forward\n",
    "cameraDirectionVector = np.array([0,0,100])\n",
    "print(cameraDirectionVector)\n",
    "\n",
    "# Camera vector after rotation (do not translate)\n",
    "# Also perform rotations to align with the robot frame, not done here\n",
    "cameraDirectionVector = np.dot(\\\n",
    "            cameraDirectionVector, redefineRotationMatrix)\n",
    "print(cameraDirectionVector)\n",
    "\n",
    "# Finding yaw of the camera vector (again, assuming no translation)\n",
    "cameraYaw = np.arctan2(cameraDirectionVector[1], cameraDirectionVector[0])\n",
    "print(cameraYaw*180/np.pi)\n",
    "\n",
    "cameraYawRange = np.array([cameraYaw+fovH, cameraYaw-fovH])\n",
    "print(cameraYawRange*180/np.pi)\n",
    "\n",
    "# Wrapping around values at -180, 180 degrees\n",
    "for n in range(len(cameraYawRange)):\n",
    "    if cameraYawRange[n]>np.pi:\n",
    "        cameraYawRange[n] -= 2*np.pi\n",
    "    if cameraYawRange[n]<=-np.pi:\n",
    "        cameraYawRange[n] += 2*np.pi\n",
    "\n",
    "cameraYawRange = np.sort(cameraYawRange)[::-1]\n",
    "\n",
    "print(cameraYawRange*180/np.pi)\n",
    "\n",
    "timeKeeper.printPerfCounter()"
   ]
  },
  {
   "source": [
    "Finding yaw of voxels within range"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(124, 3)\n",
      "(124,)\n",
      "Completed in 0.000429 seconds\n"
     ]
    }
   ],
   "source": [
    "timeKeeper.startPerfCounter()\n",
    "\n",
    "# Shifting the voxels around the camera to origin so that yaw to each voxel \n",
    "# can be found\n",
    "translatedVoxelsWithinRange = voxelsWithinRange-cameraPosition\n",
    "print(translatedVoxelsWithinRange.shape)\n",
    "\n",
    "yawToTranslatedVoxels = np.arctan2(translatedVoxelsWithinRange[:,1], \\\n",
    "                                translatedVoxelsWithinRange[:,0])\n",
    "print(yawToTranslatedVoxels.shape)\n",
    "#print(yawToTranslatedVoxels*180/np.pi)\n",
    "\n",
    "timeKeeper.printPerfCounter()"
   ]
  },
  {
   "source": [
    "Finding voxels that need to be removed"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(108, 3)\nCompleted in 0.000311 seconds\n"
     ]
    }
   ],
   "source": [
    "timeKeeper.startPerfCounter()\n",
    "\n",
    "if cameraYawRange[0]>np.pi/2 and cameraYawRange[1]<-np.pi/2:\n",
    "    voxelsToRemove = voxelsWithinRange[np.logical_and(\\\n",
    "        yawToTranslatedVoxels[:]>cameraYawRange[0], \\\n",
    "        yawToTranslatedVoxels[:]<cameraYawRange[1]\n",
    "        )]\n",
    "else:\n",
    "    voxelsToRemove = voxelsWithinRange[np.logical_and(\\\n",
    "        yawToTranslatedVoxels[:]<cameraYawRange[0], \\\n",
    "        yawToTranslatedVoxels[:]>cameraYawRange[1]\n",
    "        )]\n",
    "\n",
    "print(voxelsToRemove.shape)\n",
    "\n",
    "timeKeeper.printPerfCounter()"
   ]
  },
  {
   "source": [
    "The voxels to be removed are then removed from the base grid"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(128, 3)\n(108, 3)\n(20, 3)\n[[ 650 -350 -150]\n [ 650 -350  -50]\n [ 650 -350   50]\n [ 650 -350  150]\n [ 750 -350 -150]\n [ 750 -350  -50]\n [ 750 -350   50]\n [ 750 -350  150]\n [ 850  450 -250]\n [ 850  450 -150]\n [ 850  450  -50]\n [ 850  450   50]\n [ 850  450  150]\n [ 850  450  250]\n [ 950  450  -50]\n [ 950  450  150]\n [1450 -550  150]\n [1550 -550 -250]\n [1750 -650 -250]\n [1850 -750 -250]]\nCompleted in 0.001087 seconds\n"
     ]
    }
   ],
   "source": [
    "print(voxelGrid.shape)\n",
    "print(voxelsToRemove.shape)\n",
    "\n",
    "timeKeeper.startPerfCounter()\n",
    "\n",
    "# Found this online\n",
    "def in1d_dot_approach(A,B):\n",
    "    \"\"\"Returns the first array with elements from the second array removed\"\"\"\n",
    "    cumdims = (np.maximum(A.max(),B.max())+1)**np.arange(B.shape[1])\n",
    "    return A[~np.in1d(A.dot(cumdims),B.dot(cumdims))]\n",
    "\n",
    "voxelRemovedGrid = in1d_dot_approach(voxelGrid, voxelsToRemove)\n",
    "\n",
    "print(voxelRemovedGrid.shape)\n",
    "print(voxelRemovedGrid)\n",
    "\n",
    "timeKeeper.printPerfCounter()"
   ]
  },
  {
   "source": [
    "Combining unique voxels from voxel-removed base grid and the new voxel grid to get the updated grid"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(93, 3)\n(93, 3)\nCompleted in 0.000481 seconds\n"
     ]
    }
   ],
   "source": [
    "timeKeeper.startPerfCounter()\n",
    "\n",
    "updatedVoxelGrid = np.unique(\\\n",
    "                    np.vstack((voxelRemovedGrid, newVoxelGrid)), axis=0)\n",
    "\n",
    "print(updatedVoxelGrid.shape)\n",
    "voxelGrid = updatedVoxelGrid\n",
    "print(voxelGrid.shape)\n",
    "\n",
    "timeKeeper.printPerfCounter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be4f7a5b6c064299b6ef248b4a2749a6"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "plotGrid(voxelGrid, voxelSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}