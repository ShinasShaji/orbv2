{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python368jvsc74a57bd01b74fdc6a0069e63d7c35520416cfe241b2e1d296eedc56ee9c4fe2929446925",
   "display_name": "Python 3.6.8 64-bit ('bot': venv)",
   "language": "python"
  },
  "metadata": {
   "interpreter": {
    "hash": "1b74fdc6a0069e63d7c35520416cfe241b2e1d296eedc56ee9c4fe2929446925"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Voxel pipeline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Import requirements"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from ImageProcessor import ImageProcessor\n",
    "from StereoMatcher import StereoMatcher\n",
    "from VoxelGrid import VoxelGrid\n",
    "\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "source": [
    "### Load calibrations and other data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading from data/monoCalibration.json\nLoaded mono calibration\nReading from data/stereoCalibration.json\nLoaded stereo calibration\nReading from data/cameraProperties.json\nLoaded camera properties\nReading from data/stereoRectify.json\nLoaded stereo rectification data\n"
     ]
    }
   ],
   "source": [
    "imageProcessor = ImageProcessor()\n",
    "imageProcessor.verbose = True\n",
    "imageProcessor.loadMonoCalibrationResults()\n",
    "imageProcessor.loadStereoCalibration()\n",
    "imageProcessor.loadCameraProperties()\n",
    "imageProcessor.loadStereoRectify()"
   ]
  },
  {
   "source": [
    "### Create stereo matcher"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading from data/parametersSGBM.json\n"
     ]
    }
   ],
   "source": [
    "stereoMatcher = StereoMatcher(imageProcessor=imageProcessor, \\\n",
    "                matcher=\"SGBM\", vertical=True, createRightMatcher=False)\n",
    "\n",
    "imageProcessor.initUndistortRectifyMap()\n",
    "#stereoMatcher.createDisparityWLSFilter()"
   ]
  },
  {
   "source": [
    "### Loading images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Selections: 0-0\n"
     ]
    }
   ],
   "source": [
    "path = \"testImages/voxelTestImages\"\n",
    "imageGlobL = sorted(glob.glob(\"\".join([path, \"/top_*\", \".png\"])))\n",
    "imageGlobR = sorted(glob.glob(\"\".join([path, \"/bottom_*\", \".png\"])))\n",
    "print (\"Selections: 0-{}\".format(len(imageGlobL)-1))"
   ]
  },
  {
   "source": [
    "### Select image pair and display"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "546930c30ed64493aaa4bd12e53f770d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2178e2346d8>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "imageNumber = 0\n",
    "\n",
    "imageL = cv2.imread(imageGlobL[imageNumber])\n",
    "imageR = cv2.imread(imageGlobR[imageNumber])\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(np.hstack([imageL, imageL]), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "source": [
    "### Convert to grayscale and undistort"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageProcessor.convertToGrayscale(imageL, imageR)\n",
    "imageProcessor.undistortRectifyRemap(imageProcessor.grayImageL, \\\n",
    "                                        imageProcessor.grayImageR)"
   ]
  },
  {
   "source": [
    "### View undistorted image"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4a153d2a43d641cca675dbb7aabee34e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2178e475748>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle(\"left/right undistorted\")\n",
    "plt.imshow(cv2.cvtColor(np.hstack([imageProcessor.undistortImageL, \\\n",
    "            imageProcessor.undistortImageR]), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b966fcf2ae644ccdb8c1d0968e9c72f9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2178ebaccc0>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle(\"horizontal epipolar\")\n",
    "plt.imshow(cv2.cvtColor(imageProcessor.drawHorEpipolarLines(\\\n",
    "        imageProcessor.undistortImageL, imageProcessor.undistortImageR), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b01831250bcd4bf1bf658d2e4744711b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2178f195438>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(6,15))\n",
    "fig.suptitle(\"left/right undistorted\")\n",
    "plt.imshow(cv2.cvtColor(imageProcessor.drawVertEpipolarLines(\\\n",
    "        imageProcessor.undistortImageL, imageProcessor.undistortImageR), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "source": [
    "### Compute disparity map"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "minDisparity: 9.0\nmaxDisparity: 41.0\n"
     ]
    }
   ],
   "source": [
    "stereoMatcher.computeDisparity(\\\n",
    "                grayImageL=imageProcessor.undistortImageL, \\\n",
    "                grayImageR=imageProcessor.undistortImageR)\n",
    "\n",
    "stereoMatcher.clampDisparity()\n",
    "stereoMatcher.applyClosingFilter()\n",
    "#stereoMatcher.applyWLSFilterDisparity()\n",
    "\n",
    "print (\"minDisparity:\", stereoMatcher.disparityMapL.min())\n",
    "print (\"maxDisparity:\", stereoMatcher.disparityMapL.max())"
   ]
  },
  {
   "source": [
    "### View disparity map"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9231e76417184961b6d7dc916af76f51"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2178f0588d0>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(cv2.rotate(stereoMatcher.disparityMapL, \\\n",
    "    cv2.ROTATE_90_CLOCKWISE))"
   ]
  },
  {
   "source": [
    "### Compute depth map"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9.0\n41.0\n(640, 360)\n481.33795\n2192.7617\n"
     ]
    }
   ],
   "source": [
    "focalLength = imageProcessor.projectionMatrixL[0][0] # changes with rectify?\n",
    "baseline = 32 # mm, measured irl\n",
    "\n",
    "stereoMatcher.disparityMapL[stereoMatcher.disparityMapL==0] = 0.9\n",
    "stereoMatcher.disparityMapL[stereoMatcher.disparityMapL==-1] = 0.9\n",
    "\n",
    "depthMap = np.empty_like(stereoMatcher.disparityMapL)\n",
    "depthMap = (focalLength*baseline)/stereoMatcher.disparityMapL[:]\n",
    "\n",
    "print (stereoMatcher.disparityMapL.min())\n",
    "print (stereoMatcher.disparityMapL.max())\n",
    "print (depthMap.shape)\n",
    "print (depthMap.min())\n",
    "print (depthMap.max())"
   ]
  },
  {
   "source": [
    "### View depth map"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dadc9e14276145d7980880284dc00e74"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2178f0d6400>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(cv2.rotate(depthMap, cv2.ROTATE_90_CLOCKWISE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use to save images\n",
    "# _=cv2.imwrite(\"depth.png\", cv2.rotate(depthMap, cv2.ROTATE_90_CLOCKWISE))"
   ]
  },
  {
   "source": [
    "### Compute point cloud"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxelGrid = VoxelGrid(stereoMatcher, imageProcessor)\n",
    "voxelGrid.verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Points in unfiltered pointcloud: 11520; completed in 0.00210 sec\n"
     ]
    }
   ],
   "source": [
    "voxelGrid.generatePointCloud()"
   ]
  },
  {
   "source": [
    "Filtering extreme points"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Points in filtered pointcloud: 9245; completed in 0.00084 sec\n"
     ]
    }
   ],
   "source": [
    "voxelGrid.filterPointCloud()"
   ]
  },
  {
   "source": [
    "Rotate point cloud to have y forward"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxelGrid.redefinePointCloudCoordinate()"
   ]
  },
  {
   "source": [
    "### View point cloud"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b32853b5bcc54e4999cce27b8a51fb7f"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(7,7))\n",
    "ax = fig.add_subplot(111, projection = \"3d\")\n",
    "\n",
    "ax.scatter(voxelGrid.pointCloud[:,0], voxelGrid.pointCloud[:,1], \\\n",
    "    voxelGrid.pointCloud[:,2], s=1)\n",
    "ax.set_xlabel(\"$x$\")\n",
    "ax.set_ylabel(\"$y$\")\n",
    "ax.set_zlabel(\"$z$\")\n",
    "\n",
    "# Camera axis begins at x=0 and looks to positive x\n",
    "ax.set_xlim(0,2000)\n",
    "ax.set_ylim(-1000,1000)\n",
    "ax.set_zlim(-1000,1000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "### Voxelize point cloud"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Voxel grid reset\nVoxels in grid: 57; completed in 0.00805 sec; 61 iterations\n"
     ]
    }
   ],
   "source": [
    "voxelGrid.resetVoxelGrid()\n",
    "voxelGrid.voxelizePointCloud()"
   ]
  },
  {
   "source": [
    "### View voxelized point cloud"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a02d33dbcf54d6e946a3d3a94fda324"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(7,7))\n",
    "ax = fig.add_subplot(111, projection = \"3d\")\n",
    "\n",
    "ax.scatter(voxelGrid.voxelGrid[:,0], \\\n",
    "        voxelGrid.voxelGrid[:,1], \\\n",
    "        voxelGrid.voxelGrid[:,2])\n",
    "\n",
    "ax.set_xlabel(\"$x$\")\n",
    "ax.set_ylabel(\"$y$\")\n",
    "ax.set_zlabel(\"$z$\")\n",
    "\n",
    "# Camera axis begins at x=0 and looks to positive x\n",
    "ax.set_xlim(0,2000)\n",
    "ax.set_ylim(-1000,1000)\n",
    "ax.set_zlim(-1000,1000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "### Refine voxel grid with newer data\n",
    "\n",
    "Interchanging data from calibration since calibration was \n",
    "done vertically\n",
    "\n",
    "The x y notations are in image coordinates"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Horizontal: 24.915932084055157\nVertical: 14.867033874651561\n"
     ]
    }
   ],
   "source": [
    "# Horizontal field of view (degrees)\n",
    "fovH = ((imageProcessor.fovYL+imageProcessor.fovYR)/4)*np.pi/180\n",
    "fovH -= fovH/8\n",
    "print(\"Horizontal:\", fovH*180/np.pi)\n",
    "\n",
    "# Vertical field of view (degrees)\n",
    "fovV = ((imageProcessor.fovXL+imageProcessor.fovXR)/4)*np.pi/180\n",
    "fovV -= fovV/8\n",
    "print(\"Vertical:\", fovV*180/np.pi)"
   ]
  },
  {
   "source": [
    "### Checking for voxels in range\n",
    "\n",
    "The refinement is done by simply replacing the older voxels in view of the camera in the base grid with the new voxels.\n",
    "\n",
    "Here the voxels that may potentially be affected are found."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(57,)\n(57, 3)\n(57, 3)\n[[550, -550, -250], [1250, 250, 250]]\n"
     ]
    }
   ],
   "source": [
    "# Do this after compensations for atleast camera translation have been made\n",
    "# Performed on the base voxel grid\n",
    "# Distances to every voxel in base grid from camera\n",
    "\n",
    "# Offset camera position with distance from robot center and distance of robot \n",
    "# from origin\n",
    "# The top or left camera is taken to represent the whole camera grid\n",
    "cameraPosition = np.zeros([3])\n",
    "distanceToVoxels = np.linalg.norm(voxelGrid.voxelGrid-cameraPosition, axis=1)\n",
    "print(distanceToVoxels.shape)\n",
    "\n",
    "# Distance within which points may be modified\n",
    "distanceToCheck = 1500\n",
    "\n",
    "# These are the points to check\n",
    "# Performed on the base voxel grid\n",
    "voxelsWithinRange = voxelGrid.voxelGrid[distanceToVoxels<=distanceToCheck]\n",
    "print(voxelGrid.voxelGrid.shape)\n",
    "print(voxelsWithinRange.shape)\n",
    "\n",
    "# Checking bounds on the coordinate axes\n",
    "# Performed on the base voxel grid\n",
    "voxelCheckBound = [[voxelsWithinRange[:,0].min(), voxelsWithinRange[:,1].min(), \\\n",
    "                        voxelsWithinRange[:,2].min()], \\\n",
    "                    [voxelsWithinRange[:,0].max(), voxelsWithinRange[:,1].max(), \\\n",
    "                        voxelsWithinRange[:,2].max()]]\n",
    "print(voxelCheckBound) # min, max"
   ]
  },
  {
   "source": [
    "### Angle ranges of rotated new voxel grid (Exploration only)\n",
    "\n",
    "Could potentially be found from the rotation matrix and be offset \n",
    "by the camera fovs.\n",
    "\n",
    "Computing yaws on the new voxel grid; xy plane. A line along x axis has 0 degrees of yaw.\n",
    "\n",
    "Normally this would be the results of the latest iteration after \n",
    "they are rotated and translated.\n",
    "\n",
    "Taking x forward"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(57,)\n[ 24.443953 -25.559963]\n50.0039173665009\n"
     ]
    }
   ],
   "source": [
    "newVoxelGrid = voxelGrid.voxelGrid\n",
    "yawToNewVoxels = np.arctan2(newVoxelGrid[:,1], newVoxelGrid[:,0]) # y, x\n",
    "print(yawToNewVoxels.shape)\n",
    "\n",
    "yawCheckBound = np.array([yawToNewVoxels.max(), yawToNewVoxels.min()]) # left, right\n",
    "print(yawCheckBound*180/np.pi)\n",
    "print((yawCheckBound[0]-yawCheckBound[1])*180/np.pi)\n",
    "\n",
    "#print(yawToNewVoxels*180/np.pi)"
   ]
  },
  {
   "source": [
    "Computing pitches on the new voxel grid; xz plane.\n",
    "\n",
    "Taking x forward"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(57,)\n[ 15.255118 -15.255118]\n30.510236456393518\n"
     ]
    }
   ],
   "source": [
    "pitchToNewVoxels = np.arctan2(newVoxelGrid[:,2], newVoxelGrid[:,0])\n",
    "print(pitchToNewVoxels.shape)\n",
    "\n",
    "                                                                # up, down\n",
    "pitchCheckBound = np.array([pitchToNewVoxels.max(), pitchToNewVoxels.min()]) \n",
    "print(pitchCheckBound*180/np.pi)\n",
    "print((pitchCheckBound[0]-pitchCheckBound[1])*180/np.pi)\n",
    "\n",
    "#print(pitchToNewVoxels*180/np.pi)"
   ]
  },
  {
   "source": [
    "Computing rolls on the new voxel grid; yz plane.\n",
    "\n",
    "Taking x forward"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(57,)\n[ 171.86989 -174.80557]\n346.67548573975506\n"
     ]
    }
   ],
   "source": [
    "rollToNewVoxels = np.arctan2(newVoxelGrid[:,2], newVoxelGrid[:,1])\n",
    "print(rollToNewVoxels.shape)\n",
    "\n",
    "rollCheckBound = np.array([rollToNewVoxels.max(), rollToNewVoxels.min()])\n",
    "print(rollCheckBound*180/np.pi)\n",
    "print((rollCheckBound[0]-rollCheckBound[1])*180/np.pi)\n",
    "\n",
    "#print(rollToNewVoxels*180/np.pi)"
   ]
  },
  {
   "source": [
    "From the results above, checking for pitch and roll will return \n",
    "inconclusive results unless the rotation is in an exact side profile of the\n",
    "grid.\n",
    "\n",
    "This can be mitigated by doing the check before rotating or translating, but that would require the base grid to be rotated as a whole, refined, and then re-rotated back.\n",
    "\n",
    "To save on computation, the yaw range for the new voxel grid may simply be taken from camera properties already found during calibration. \n",
    "\n",
    "Then, to check where the camera is facing, a vector of unit distance from the camera facing along its axis could be rotated and translated along with the camera. \n",
    "\n",
    "Its yaw with respect to the camera center can then be calculated, and then offset by half its horizontal fov on both sides, to find the yaw limits within which the base voxels may be modified."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Finding yaw of camera and voxels within range\n",
    "Finding yaw of camera"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[  0   0 100]\n",
      "[100   0   0]\n",
      "0.0\n",
      "[ 0.43486505 -0.43486505]\n",
      "[ 24.91593208 -24.91593208]\n",
      "[ 0.43486505 -0.43486505]\n",
      "[ 24.91593208 -24.91593208]\n"
     ]
    }
   ],
   "source": [
    "# Camera vector before rotation, z forward\n",
    "cameraDirectionVector = np.array([0,0,100])\n",
    "print(cameraDirectionVector)\n",
    "\n",
    "# Camera vector after rotation (do not translate)\n",
    "# Also perform rotations to align with the robot frame, not done here\n",
    "cameraDirectionVector = np.dot(\\\n",
    "            cameraDirectionVector, voxelGrid.redefineRotationMatrix)\n",
    "print(cameraDirectionVector)\n",
    "\n",
    "# Finding yaw of the camera vector (again, assuming no translation)\n",
    "cameraYaw = np.arctan2(cameraDirectionVector[1], cameraDirectionVector[0])\n",
    "print(cameraYaw*180/np.pi)\n",
    "\n",
    "cameraYawRange = np.array([cameraYaw+fovH, cameraYaw-fovH])\n",
    "print(cameraYawRange)\n",
    "print(cameraYawRange*180/np.pi)\n",
    "\n",
    "# Wrapping around values at -180, 180 degrees\n",
    "for n in range(len(cameraYawRange)):\n",
    "    if cameraYawRange[n]>np.pi:\n",
    "        cameraYawRange[n] -= 2*np.pi\n",
    "    if cameraYawRange[n]<=-np.pi:\n",
    "        cameraYawRange[n] += 2*np.pi\n",
    "\n",
    "cameraYawRange = np.sort(cameraYawRange)[::-1]\n",
    "\n",
    "print(cameraYawRange)\n",
    "print(cameraYawRange*180/np.pi)"
   ]
  },
  {
   "source": [
    "Finding yaw of voxels within range"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(57, 3)\n(57,)\n"
     ]
    }
   ],
   "source": [
    "# Shifting the voxels around the camera to origin so that yaw to each voxel \n",
    "# can be found\n",
    "translatedVoxelsWithinRange = voxelsWithinRange-cameraPosition\n",
    "print(translatedVoxelsWithinRange.shape)\n",
    "\n",
    "yawToTranslatedVoxels = np.arctan2(translatedVoxelsWithinRange[:,1], \\\n",
    "                                translatedVoxelsWithinRange[:,0])\n",
    "print(yawToTranslatedVoxels.shape)\n",
    "#print(yawToTranslatedVoxels*180/np.pi)"
   ]
  },
  {
   "source": [
    "Finding voxels that need to be removed"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(56, 3)\n"
     ]
    }
   ],
   "source": [
    "if cameraYawRange[0]>np.pi/2 and cameraYawRange[1]<-np.pi/2:\n",
    "    voxelsToRemove = voxelsWithinRange[np.logical_and(\\\n",
    "        yawToTranslatedVoxels[:]>cameraYawRange[0], \\\n",
    "        yawToTranslatedVoxels[:]<cameraYawRange[1]\n",
    "        )]\n",
    "else:\n",
    "    voxelsToRemove = voxelsWithinRange[np.logical_and(\\\n",
    "        yawToTranslatedVoxels[:]<cameraYawRange[0], \\\n",
    "        yawToTranslatedVoxels[:]>cameraYawRange[1]\n",
    "        )]\n",
    "\n",
    "print(voxelsToRemove.shape)"
   ]
  },
  {
   "source": [
    "The voxels to be removed are then removed from the base grid"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(57, 3)\n",
      "(56, 3)\n",
      "(1, 3)\n",
      "[[1150 -550  -50]]\n"
     ]
    }
   ],
   "source": [
    "print(voxelGrid.voxelGrid.shape)\r\n",
    "print(voxelsToRemove.shape)\r\n",
    "\r\n",
    "# Found this online\r\n",
    "def in1d_dot_approach(A,B):\r\n",
    "    \"\"\"Returns the first array with elements from the second array removed\"\"\"\r\n",
    "    cumdims = (np.maximum(A.max(),B.max())+1)**np.arange(B.shape[1])\r\n",
    "    return A[~np.in1d(A.dot(cumdims),B.dot(cumdims))]\r\n",
    "\r\n",
    "voxelRemovedGrid = in1d_dot_approach(voxelGrid.voxelGrid, voxelsToRemove)\r\n",
    "print(voxelRemovedGrid.shape)\r\n",
    "print(voxelRemovedGrid)"
   ]
  },
  {
   "source": [
    "Combining unique voxels from voxel-removed base grid and the new voxel grid to get the updated grid"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(57, 3)\n(57, 3)\n"
     ]
    }
   ],
   "source": [
    "updatedVoxelGrid = np.unique(\\\n",
    "                    np.vstack((voxelRemovedGrid, newVoxelGrid)), axis=0)\n",
    "print(updatedVoxelGrid.shape)\n",
    "voxelGrid.voxelGrid = updatedVoxelGrid\n",
    "print(voxelGrid.voxelGrid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}