{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python368jvsc74a57bd01b74fdc6a0069e63d7c35520416cfe241b2e1d296eedc56ee9c4fe2929446925",
   "display_name": "Python 3.6.8 64-bit ('bot': venv)",
   "language": "python"
  },
  "metadata": {
   "interpreter": {
    "hash": "1b74fdc6a0069e63d7c35520416cfe241b2e1d296eedc56ee9c4fe2929446925"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Voxel pipeline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Import requirements"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from ImageProcessor import ImageProcessor\n",
    "from StereoMatcher import StereoMatcher\n",
    "from VoxelGrid import VoxelGrid\n",
    "\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "source": [
    "### Load calibrations and other data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading from data/monoCalibration.json\nLoaded mono calibration\nReading from data/stereoCalibration.json\nLoaded stereo calibration\nReading from data/cameraProperties.json\nLoaded camera properties\nReading from data/stereoRectify.json\nLoaded stereo rectification data\n"
     ]
    }
   ],
   "source": [
    "imageProcessor = ImageProcessor()\n",
    "imageProcessor.verbose = True\n",
    "imageProcessor.loadMonoCalibrationResults()\n",
    "imageProcessor.loadStereoCalibration()\n",
    "imageProcessor.loadCameraProperties()\n",
    "imageProcessor.loadStereoRectify()"
   ]
  },
  {
   "source": [
    "### Create stereo matcher"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading from data/parametersSGBM.json\n"
     ]
    }
   ],
   "source": [
    "stereoMatcher = StereoMatcher(imageProcessor=imageProcessor, \\\n",
    "                matcher=\"SGBM\", vertical=True, createRightMatcher=False)\n",
    "\n",
    "imageProcessor.initUndistortRectifyMap()\n",
    "#stereoMatcher.createDisparityWLSFilter()"
   ]
  },
  {
   "source": [
    "### Loading images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Selections: 0-0\n"
     ]
    }
   ],
   "source": [
    "path = \"testImages/voxelTestImages\"\n",
    "imageGlobL = sorted(glob.glob(\"\".join([path, \"/top_*\", \".png\"])))\n",
    "imageGlobR = sorted(glob.glob(\"\".join([path, \"/bottom_*\", \".png\"])))\n",
    "print (\"Selections: 0-{}\".format(len(imageGlobL)-1))"
   ]
  },
  {
   "source": [
    "### Select image pair and display"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fed1a1ff96b84299a88a91a6f8d8e5cb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2490ea68c18>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "imageNumber = 0\n",
    "\n",
    "imageL = cv2.imread(imageGlobL[imageNumber])\n",
    "imageR = cv2.imread(imageGlobR[imageNumber])\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(np.hstack([imageL, imageL]), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "source": [
    "### Convert to grayscale and undistort"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageProcessor.convertToGrayscale(imageL, imageR)\n",
    "imageProcessor.undistortRectifyRemap(imageProcessor.grayImageL, \\\n",
    "                                        imageProcessor.grayImageR)"
   ]
  },
  {
   "source": [
    "### View undistorted image"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "089e617e156f4e239ff32127b932efb8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2490eca9c88>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle(\"left/right undistorted\")\n",
    "plt.imshow(cv2.cvtColor(np.hstack([imageProcessor.undistortImageL, \\\n",
    "            imageProcessor.undistortImageR]), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6ad840a081864bd8844b5c251aad37a5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2490f3bd278>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle(\"horizontal epipolar\")\n",
    "plt.imshow(cv2.cvtColor(imageProcessor.drawHorEpipolarLines(\\\n",
    "        imageProcessor.undistortImageL, imageProcessor.undistortImageR), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2fe7612e0fc4efe838fe3a4126393e0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2490f428a90>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(6,15))\n",
    "fig.suptitle(\"left/right undistorted\")\n",
    "plt.imshow(cv2.cvtColor(imageProcessor.drawVertEpipolarLines(\\\n",
    "        imageProcessor.undistortImageL, imageProcessor.undistortImageR), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "source": [
    "### Compute disparity map"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "minDisparity: 9.0\nmaxDisparity: 41.0\n"
     ]
    }
   ],
   "source": [
    "stereoMatcher.computeDisparity(\\\n",
    "                grayImageL=imageProcessor.undistortImageL, \\\n",
    "                grayImageR=imageProcessor.undistortImageR)\n",
    "\n",
    "stereoMatcher.clampDisparity()\n",
    "stereoMatcher.applyClosingFilter()\n",
    "#stereoMatcher.applyWLSFilterDisparity()\n",
    "\n",
    "print (\"minDisparity:\", stereoMatcher.disparityMapL.min())\n",
    "print (\"maxDisparity:\", stereoMatcher.disparityMapL.max())"
   ]
  },
  {
   "source": [
    "### View disparity map"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb6f0038c4cc41228f95773cd641641a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2490f48bf28>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(cv2.rotate(stereoMatcher.disparityMapL, \\\n",
    "    cv2.ROTATE_90_CLOCKWISE))"
   ]
  },
  {
   "source": [
    "### Compute depth map"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9.0\n41.0\n(640, 360)\n481.33795\n2192.7617\n"
     ]
    }
   ],
   "source": [
    "focalLength = imageProcessor.projectionMatrixL[0][0] # changes with rectify?\n",
    "baseline = 32 # mm, measured irl\n",
    "\n",
    "stereoMatcher.disparityMapL[stereoMatcher.disparityMapL==0] = 0.9\n",
    "stereoMatcher.disparityMapL[stereoMatcher.disparityMapL==-1] = 0.9\n",
    "\n",
    "depthMap = np.empty_like(stereoMatcher.disparityMapL)\n",
    "depthMap = (focalLength*baseline)/stereoMatcher.disparityMapL[:]\n",
    "\n",
    "print (stereoMatcher.disparityMapL.min())\n",
    "print (stereoMatcher.disparityMapL.max())\n",
    "print (depthMap.shape)\n",
    "print (depthMap.min())\n",
    "print (depthMap.max())"
   ]
  },
  {
   "source": [
    "### View depth map"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a5904502dc9415c93b7358bf1a9a18a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2490f508978>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(cv2.rotate(depthMap, cv2.ROTATE_90_CLOCKWISE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use to save images\n",
    "# _=cv2.imwrite(\"depth.png\", cv2.rotate(depthMap, cv2.ROTATE_90_CLOCKWISE))"
   ]
  },
  {
   "source": [
    "### Compute point cloud"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxelGrid = VoxelGrid(stereoMatcher, imageProcessor)\n",
    "voxelGrid.verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Points in unfiltered pointcloud: 11520; completed in 0.00203 sec\n"
     ]
    }
   ],
   "source": [
    "voxelGrid.generatePointCloud()"
   ]
  },
  {
   "source": [
    "Filtering extreme points"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Points in filtered pointcloud: 9245; completed in 0.00076 sec\n"
     ]
    }
   ],
   "source": [
    "voxelGrid.filterPointCloud()"
   ]
  },
  {
   "source": [
    "Rotate point cloud to have y forward"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxelGrid.redefinePointCloudCoordinate()"
   ]
  },
  {
   "source": [
    "### View point cloud"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6718000666954f74bb2ff3c281559fe1"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(7,7))\n",
    "ax = fig.add_subplot(111, projection = \"3d\")\n",
    "\n",
    "ax.scatter(voxelGrid.pointCloud[:,0], voxelGrid.pointCloud[:,1], \\\n",
    "    voxelGrid.pointCloud[:,2], s=1)\n",
    "ax.set_xlabel(\"$x$\")\n",
    "ax.set_ylabel(\"$y$\")\n",
    "ax.set_zlabel(\"$z$\")\n",
    "\n",
    "# Camera axis begins at x=0 and looks to positive x\n",
    "ax.set_xlim(0,2000)\n",
    "ax.set_ylim(-1000,1000)\n",
    "ax.set_zlim(-1000,1000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "### Voxelize point cloud"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Voxel grid reset\nVoxels in grid: 59; completed in 0.00913 sec; 70 iterations\n"
     ]
    }
   ],
   "source": [
    "voxelGrid.resetVoxelGrid()\n",
    "voxelGrid.voxelizePointCloud()"
   ]
  },
  {
   "source": [
    "### View voxelized point cloud"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f1ca39f6b7074edd85943ee236d6af13"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(7,7))\n",
    "ax = fig.add_subplot(111, projection = \"3d\")\n",
    "\n",
    "ax.scatter(voxelGrid.voxelGrid[:,0], \\\n",
    "        voxelGrid.voxelGrid[:,1], \\\n",
    "        voxelGrid.voxelGrid[:,2])\n",
    "\n",
    "ax.set_xlabel(\"$x$\")\n",
    "ax.set_ylabel(\"$y$\")\n",
    "ax.set_zlabel(\"$z$\")\n",
    "\n",
    "# Camera axis begins at x=0 and looks to positive x\n",
    "ax.set_xlim(0,2000)\n",
    "ax.set_ylim(-1000,1000)\n",
    "ax.set_zlim(-1000,1000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "### Refine voxel grid with newer data\n",
    "\n",
    "Interchanging data from calibration since calibration was \n",
    "done vertically\n",
    "\n",
    "The x y notations are in image coordinates"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Horizontal: 24.915932084055157\nVertical: 14.867033874651561\n"
     ]
    }
   ],
   "source": [
    "# Horizontal field of view (degrees)\n",
    "fovH = ((imageProcessor.fovYL+imageProcessor.fovYR)/4)*np.pi/180\n",
    "fovH -= fovH/8\n",
    "print(\"Horizontal:\", fovH*180/np.pi)\n",
    "\n",
    "# Vertical field of view (degrees)\n",
    "fovV = ((imageProcessor.fovXL+imageProcessor.fovXR)/4)*np.pi/180\n",
    "fovV -= fovV/8\n",
    "print(\"Vertical:\", fovV*180/np.pi)"
   ]
  },
  {
   "source": [
    "### Checking for voxels in range\n",
    "\n",
    "The refinement is done by simply replacing the older voxels in view of the camera in the base gridwith the new voxels.\n",
    "\n",
    "Here the voxels that may potentially be affected are found."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(59,)\n(59, 3)\n(59, 3)\n[[550, -550, -250], [1150, 250, 250]]\n"
     ]
    }
   ],
   "source": [
    "# Do this after compensations for atleast camera translation have been made\n",
    "# Performed on the base voxel grid\n",
    "# Distances to every voxel in base grid from camera\n",
    "\n",
    "# Offset camera position with distance from robot center and distance of robot \n",
    "# from origin\n",
    "# The top or left camera is taken to represent the whole camera grid\n",
    "cameraPosition = np.zeros([3])\n",
    "distanceToVoxels = np.linalg.norm(voxelGrid.voxelGrid-cameraPosition, axis=1)\n",
    "print(distanceToVoxels.shape)\n",
    "\n",
    "# Distance within which points may be modified\n",
    "distanceToCheck = 1500\n",
    "\n",
    "# These are the points to check\n",
    "# Performed on the base voxel grid\n",
    "voxelsWithinRange = voxelGrid.voxelGrid[distanceToVoxels<=distanceToCheck]\n",
    "print(voxelGrid.voxelGrid.shape)\n",
    "print(voxelsWithinRange.shape)\n",
    "\n",
    "# Checking bounds on the coordinate axes\n",
    "# Performed on the base voxel grid\n",
    "voxelCheckBound = [[voxelsWithinRange[:,0].min(), voxelsWithinRange[:,1].min(), \\\n",
    "                        voxelsWithinRange[:,2].min()], \\\n",
    "                    [voxelsWithinRange[:,0].max(), voxelsWithinRange[:,1].max(), \\\n",
    "                        voxelsWithinRange[:,2].max()]]\n",
    "print(voxelCheckBound) # min, max"
   ]
  },
  {
   "source": [
    "### Angle ranges of rotated new voxel grid (Exploration only)\n",
    "\n",
    "Could potentially be found from the rotation matrix and be offset \n",
    "by the camera fovs.\n",
    "\n",
    "Computing yaws on the new voxel grid; xy plane. A line along x axis has 0 degrees of yaw.\n",
    "\n",
    "Normally this would be the results of the latest iteration after \n",
    "they are rotated and translated.\n",
    "\n",
    "Taking x forward"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(59,)\n[ 24.443953 -25.559963]\n50.0039173665009\n"
     ]
    }
   ],
   "source": [
    "newVoxelGrid = voxelGrid.voxelGrid\n",
    "yawToNewVoxels = np.arctan2(newVoxelGrid[:,1], newVoxelGrid[:,0]) # y, x\n",
    "print(yawToNewVoxels.shape)\n",
    "\n",
    "yawCheckBound = np.array([yawToNewVoxels.max(), yawToNewVoxels.min()]) # left, right\n",
    "print(yawCheckBound*180/np.pi)\n",
    "print((yawCheckBound[0]-yawCheckBound[1])*180/np.pi)\n",
    "\n",
    "#print(yawToNewVoxels*180/np.pi)"
   ]
  },
  {
   "source": [
    "Computing pitches on the new voxel grid; xz plane.\n",
    "\n",
    "Taking x forward"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(59,)\n[ 14.743562 -16.38954 ]\n31.13310189737449\n"
     ]
    }
   ],
   "source": [
    "pitchToNewVoxels = np.arctan2(newVoxelGrid[:,2], newVoxelGrid[:,0])\n",
    "print(pitchToNewVoxels.shape)\n",
    "\n",
    "                                                                # up, down\n",
    "pitchCheckBound = np.array([pitchToNewVoxels.max(), pitchToNewVoxels.min()]) \n",
    "print(pitchCheckBound*180/np.pi)\n",
    "print((pitchCheckBound[0]-pitchCheckBound[1])*180/np.pi)\n",
    "\n",
    "#print(pitchToNewVoxels*180/np.pi)"
   ]
  },
  {
   "source": [
    "Computing rolls on the new voxel grid; yz plane.\n",
    "\n",
    "Taking x forward"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(59,)\n[ 173.65982 -173.65982]\n347.3196272200006\n"
     ]
    }
   ],
   "source": [
    "rollToNewVoxels = np.arctan2(newVoxelGrid[:,2], newVoxelGrid[:,1])\n",
    "print(rollToNewVoxels.shape)\n",
    "\n",
    "rollCheckBound = np.array([rollToNewVoxels.max(), rollToNewVoxels.min()])\n",
    "print(rollCheckBound*180/np.pi)\n",
    "print((rollCheckBound[0]-rollCheckBound[1])*180/np.pi)\n",
    "\n",
    "#print(rollToNewVoxels*180/np.pi)"
   ]
  },
  {
   "source": [
    "From the results above, checking for pitch and roll will return \n",
    "inconclusive results unless the rotation is in an exact side profile of the\n",
    "grid.\n",
    "\n",
    "This can be mitigated by doing the check before rotating or translating, but that would require the base grid to be rotated as a whole, refined, and then re-rotated back.\n",
    "\n",
    "To save on computation, the yaw range for the new voxel grid may simply be taken from camera properties already found during calibration. \n",
    "\n",
    "Then, to check where the camera is facing, a vector of unit distance from the camera facing along its axis could be rotated and translated along with the camera. \n",
    "\n",
    "Its yaw with respect to the camera center can then be calculated, and then offset by half its horizontal fov on both sides, to find the yaw limits within which the base voxels may be modified."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Finding yaw of camera and voxels within range\n",
    "Finding yaw of camera"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[  0   0 100]\n[100   0   0]\n0.0\n[ 0.43486505 -0.43486505]\n[ 24.91593208 -24.91593208]\n[ 0.43486505 -0.43486505]\n[ 24.91593208 -24.91593208]\n"
     ]
    }
   ],
   "source": [
    "# Camera vector before rotation, z forward\n",
    "cameraDirectionVector = np.array([0,0,100])\n",
    "print(cameraDirectionVector)\n",
    "\n",
    "# Camera vector after rotation (do not translate)\n",
    "# Also perform rotations to align with the robot frame, not done here\n",
    "cameraDirectionVector = np.dot(\\\n",
    "            cameraDirectionVector, voxelGrid.redefineRotationMatrix)\n",
    "print(cameraDirectionVector)\n",
    "\n",
    "# Finding yaw of the camera vector (again, assuming no translation)\n",
    "cameraYaw = np.arctan2(cameraDirectionVector[1], cameraDirectionVector[0])\n",
    "print(cameraYaw*180/np.pi)\n",
    "\n",
    "cameraYawRange = np.array([cameraYaw+fovH, cameraYaw-fovH])\n",
    "print(cameraYawRange)\n",
    "print(cameraYawRange*180/np.pi)\n",
    "\n",
    "# Wrapping around values at -180, 180 degrees\n",
    "for n in range(len(cameraYawRange)):\n",
    "    if cameraYawRange[n]>np.pi:\n",
    "        cameraYawRange[n] -= 2*np.pi\n",
    "    if cameraYawRange[n]<=-np.pi:\n",
    "        cameraYawRange[n] += 2*np.pi\n",
    "\n",
    "cameraYawRange = np.sort(cameraYawRange)[::-1]\n",
    "\n",
    "print(cameraYawRange)\n",
    "print(cameraYawRange*180/np.pi)"
   ]
  },
  {
   "source": [
    "Finding yaw of voxels within range"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(59, 3)\n(59,)\n"
     ]
    }
   ],
   "source": [
    "# Shifting the voxels around the camera to origin so that yaw to each voxel \n",
    "# can be found\n",
    "translatedVoxelsWithinRange = voxelsWithinRange-cameraPosition\n",
    "print(translatedVoxelsWithinRange.shape)\n",
    "\n",
    "yawToTranslatedVoxels = np.arctan2(translatedVoxelsWithinRange[:,1], \\\n",
    "                                translatedVoxelsWithinRange[:,0])\n",
    "print(yawToTranslatedVoxels.shape)\n",
    "#print(yawToTranslatedVoxels*180/np.pi)"
   ]
  },
  {
   "source": [
    "Finding voxels that need to be removed"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(57, 3)\n"
     ]
    }
   ],
   "source": [
    "if cameraYawRange[0]>np.pi/2 and cameraYawRange[1]<-np.pi/2:\n",
    "    voxelsToRemove = voxelsWithinRange[np.logical_and(\\\n",
    "        yawToTranslatedVoxels[:]>cameraYawRange[0], \\\n",
    "        yawToTranslatedVoxels[:]<cameraYawRange[1]\n",
    "        )]\n",
    "else:\n",
    "    voxelsToRemove = voxelsWithinRange[np.logical_and(\\\n",
    "        yawToTranslatedVoxels[:]<cameraYawRange[0], \\\n",
    "        yawToTranslatedVoxels[:]>cameraYawRange[1]\n",
    "        )]\n",
    "\n",
    "print(voxelsToRemove.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}